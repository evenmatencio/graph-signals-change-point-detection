{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data pre-processing and exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import scipy\n",
    "\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pyedflib import highlevel\n",
    "from libpysal.weights import KNN\n",
    "from pathlib import Path\n",
    "\n",
    "import utils as my_ut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wind Spatio-Temporal Dataset\n",
    "\n",
    "The dataset we use in the following part is the [Wind Spatio-Temporal Dataset2](https://zenodo.org/records/5516550). We extract the values corresponding to the wind speed and the power for the 200 turbines. Such values are the considered multivariate time series. We also use the coordinates of the turbines to turn our time signals into a grap time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv(\"data/Wind_Turbines/Wind Spatio-Temporal Dataset2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the turbine coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord = data_df.iloc[0:2].copy(deep=True)\n",
    "col_names = [\"Unnamed: 0\"] + [f'Turbine{i}' for i in range(1, 201)]\n",
    "coord = coord[col_names]\n",
    "coord.set_index('Unnamed: 0', inplace=True)\n",
    "coord.index.name = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord.to_csv('data/turbines_coord.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the speed and power time series per turbine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_power_df = data_df.iloc[3:len(data_df.index)].copy(deep=True)\n",
    "speed_power_df.columns = speed_power_df.loc[3]\n",
    "speed_power_df.drop(speed_power_df.index[0], inplace=True)\n",
    "speed_power_df = speed_power_df.drop(['Mast1_Speed', 'Mast2_Speed', \"Mast3_Speed\", \"Mast1_Direction\", 'Mast2_Direction', \"Mast3_Direction\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_power_df.to_csv('data/turbines_speed_power.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CHB-MIT_Scalp_EEG\n",
    "\n",
    "The following data comes from [CHB-MIT Scalp EEG Database](https://physionet.org/content/chbmit/1.0.0/chb01/#files-panel). It consists of a collection of EEG recordings of 22 pediatric subjects with intractable seizures. For each subject, a number of *.edf* files were recorded containing generally one hour of digitized EEG signals, recorded with International 10-20 system of EEG electrode positions and nomenclature.\n",
    "\n",
    "Please refer to this [learning eeg presentation](https://www.learningeeg.com/montages-and-technical-components) for details about the nomenclature of the channels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opening and vizualization of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signals_03, signal_headers_03, header_03 = highlevel.read_edf('data/CHB-MIT_Scalp_EEG/chb01_03.edf')\n",
    "signals_03.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_freq = int(signal_headers_03[0]['sample_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seizure_start_03 = 2996\n",
    "seizure_end_03 = 3036\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(20, 4))\n",
    "ax.plot(signals_03[0, :])\n",
    "ax.axvline(x=sample_freq*seizure_start_03, color='k')\n",
    "ax.axvline(x=sample_freq*seizure_end_03, color='k')\n",
    "new_labels = [str(int(label._text)//sample_freq) for label in ax.get_xticklabels()[1:-1]]\n",
    "ax.set_xticks(ax.get_xticks()[1:-1], new_labels)\n",
    "ax.set_xlabel('Time (s)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_start_03 = (seizure_start_03 - 10) * sample_freq\n",
    "plot_end_03 = (seizure_end_03 + 10) * sample_freq\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(20, 4))\n",
    "ax.plot(signals_03[0, plot_start_03:plot_end_03])\n",
    "ax.axvline(x=sample_freq*seizure_start_03 - plot_start_03, color='k')\n",
    "ax.axvline(x=sample_freq*seizure_end_03 - plot_start_03, color='k')\n",
    "new_labels = [str(int(label._text)//sample_freq + plot_start_03//sample_freq) for label in ax.get_xticklabels()[1:-1]]\n",
    "ax.set_xticks(ax.get_xticks()[1:-1], new_labels)\n",
    "ax.set_xlabel('Time (s)')\n",
    "print(sample_freq*seizure_start_03 - plot_start_03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_start_03 = (seizure_start_03 - 20) * sample_freq\n",
    "plot_end_03 = (seizure_end_03 + 20) * sample_freq\n",
    "\n",
    "nb_channel_to_show = 20\n",
    "fig, axes = plt.subplots(nb_channel_to_show, 1, figsize=(20, nb_channel_to_show//2+5))\n",
    "for i in range(nb_channel_to_show):\n",
    "    axes[i].plot(signals_03[i, plot_start_03:plot_end_03])\n",
    "    axes[i].axvline(x=sample_freq*seizure_start_03 - plot_start_03, color='k')\n",
    "    axes[i].axvline(x=sample_freq*seizure_end_03 - plot_start_03, color='k')\n",
    "    axes[i].axis('off')\n",
    "new_labels = [str(int(label._text)//sample_freq + plot_start_03//sample_freq) for label in ax.get_xticklabels()[1:-1]]\n",
    "axes[-1].axis('on')\n",
    "axes[-1].spines['right'].set_visible(False)\n",
    "axes[-1].spines['top'].set_visible(False)\n",
    "axes[-1].spines['left'].set_visible(False)\n",
    "axes[-1].get_yaxis().set_visible(False)\n",
    "axes[-1].set_xticks(ax.get_xticks()[1:-1], new_labels)\n",
    "axes[-1].set_xlabel('Time (s)')\n",
    "fig.suptitle(f'Channels from chb01_03')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signals_04, signal_headers_04, header_04 = highlevel.read_edf('data/CHB-MIT_Scalp_EEG/chb01_04.edf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seizure_start_04 = 1467\n",
    "seizure_end_04 = 1494\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(20, 4))\n",
    "ax.plot(signals_04[0, :])\n",
    "ax.axvline(x=sample_freq*seizure_start_04, color='k')\n",
    "ax.axvline(x=sample_freq*seizure_end_04, color='k')\n",
    "new_labels = [str(int(label._text)//sample_freq) for label in ax.get_xticklabels()[1:-1]]\n",
    "ax.set_xticks(ax.get_xticks()[1:-1], new_labels)\n",
    "ax.set_xlabel('Time (s)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_start_04 = (seizure_start_04 - 10) * sample_freq\n",
    "plot_end_04 = (seizure_end_04 + 10) * sample_freq\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(20, 4))\n",
    "ax.plot(signals_04[0, plot_start_04:plot_end_04])\n",
    "ax.axvline(x=sample_freq*seizure_start_04 - plot_start_04, color='k')\n",
    "ax.axvline(x=sample_freq*seizure_end_04- plot_start_04, color='k')\n",
    "new_labels = [str(int(label._text)//sample_freq + plot_start_04//sample_freq) for label in ax.get_xticklabels()[1:-1]]\n",
    "ax.set_xticks(ax.get_xticks()[1:-1], new_labels)\n",
    "ax.set_xlabel('Time (s)')\n",
    "print(sample_freq*seizure_start_04 - plot_start_04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_start_04 = (seizure_start_04 - 20) * sample_freq\n",
    "plot_end_04 = (seizure_end_04 + 20) * sample_freq\n",
    "\n",
    "nb_channel_to_show = 20\n",
    "fig, axes = plt.subplots(nb_channel_to_show, 1, figsize=(20, nb_channel_to_show//2+5))\n",
    "for i in range(nb_channel_to_show):\n",
    "    axes[i].plot(signals_04[i, plot_start_04:plot_end_04])\n",
    "    axes[i].axvline(x=sample_freq*seizure_start_04 - plot_start_04, color='k')\n",
    "    axes[i].axvline(x=sample_freq*seizure_end_04 - plot_start_04, color='k')\n",
    "    axes[i].axis('off')\n",
    "new_labels = [str(int(label._text)//sample_freq + plot_start_04//sample_freq) for label in ax.get_xticklabels()[1:-1]]\n",
    "axes[-1].axis('on')\n",
    "axes[-1].spines['right'].set_visible(False)\n",
    "axes[-1].spines['top'].set_visible(False)\n",
    "axes[-1].spines['left'].set_visible(False)\n",
    "axes[-1].get_yaxis().set_visible(False)\n",
    "axes[-1].set_xticks(ax.get_xticks()[1:-1], new_labels)\n",
    "axes[-1].set_xlabel('Time (s)')\n",
    "fig.suptitle(f'Channels from chb01_04')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EEG Motor Movement/Imagery Dataset\n",
    "\n",
    "This data set consists of over 1500 one- and two-minute EEG recordings from [PhysioNet EEG Motor Movement](https://physionet.org/content/eegmmidb/1.0.0/), obtained from 109 volunteers. Subjects performed different motor/imagery tasks while 64-channel EEG were recorded using the BCI2000 system (http://www.bci2000.org). Each subject performed 14 experimental runs: two one-minute baseline runs (one with eyes open, one with eyes closed), and three two-minute runs of each of four tasks. \n",
    "\n",
    "All files contain 64 EEG signals, each sampled at 160 samples per second, and an annotation channel.For each experimental run, temporal segments corresponding to different activity are annotated with **T0**, **T1** or **T2**. Te exact activity depends on the experimental run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing \n",
    "\n",
    "**Objectives:**\n",
    "\n",
    "- check the quality of the channels: create a function to visualize all channels\n",
    "- produce some utils: turn the change-points in sec into array indices\n",
    "- apply the filtering pre-processing and visualize again: use scikit learn or mne\n",
    "- create the graph: see on mne if something exists, otherwise name the nodes and create edges based on node names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def turn_time_cp_into_indices_cp(annotations, sampling_freq, last_ind):\n",
    "    indices_cp = []\n",
    "    for cp_data in annotations[:-1]:\n",
    "        time_cp = (cp_data[0] + cp_data[1]) * sampling_freq\n",
    "        indices_cp.append(int(time_cp))\n",
    "    indices_cp.append(last_ind)\n",
    "    return indices_cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_selected_channels(selected_channels, signal, signal_headers, plot_start, plot_end, sampling_freq):\n",
    "    n_channel_to_show = len(selected_channels)\n",
    "    fig, axes = plt.subplots(n_channel_to_show, 1, figsize=(20, n_channel_to_show//2+5))\n",
    "    # iterating over all the channels except the last one\n",
    "    for ax_i, i in enumerate(selected_channels[:-1]):\n",
    "        axes[ax_i].plot(signal[i, plot_start:plot_end])\n",
    "        axes[ax_i].set_ylabel(signal_headers[i]['label'])\n",
    "        axes[ax_i].set_xticks([], [])\n",
    "        axes[ax_i].set_yticks([], [])\n",
    "        for key, spine in axes[ax_i].spines.items():\n",
    "            spine.set_visible(False)\n",
    "    # specific processing of the last channel\n",
    "    axes[-1].plot(signal[selected_channels[-1], plot_start:plot_end])\n",
    "    axes[-1].set_yticks([], [])\n",
    "    for _, spine in axes[-1].spines.items():\n",
    "        spine.set_visible(False)\n",
    "    new_labels = [str(int(label._text)//sampling_freq + plot_start//sampling_freq) for label in axes[-1].get_xticklabels()[1:-1]]\n",
    "    axes[-1].set_xticks(axes[-1].get_xticks()[1:-1], new_labels)\n",
    "    axes[-1].set_xlabel('Time (s)')\n",
    "    return fig, axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_bkps_to_plot(axes, bkps_ids, color):\n",
    "    for ax in axes:\n",
    "        for bkp_id in bkps_ids:\n",
    "            ax.axvline(x=bkp_id, color=color)\n",
    "    return axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_signal(signal, filter_order, low_cutoff, high_cutoff):\n",
    "    sos_filter = scipy.signal.butter(N=filter_order, Wn=[low_cutoff, high_cutoff], btype='bandpass', fs=sample_freq, output='sos')\n",
    "    filtered_signal = np.empty(signal.shape)\n",
    "    for i in range(signal.shape[0]):\n",
    "        filtered_signal[i, :] = scipy.signal.sosfilt(sos_filter, signal[i, :])\n",
    "    return filtered_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsample_signal(signal, sub_freq, sample_freq):\n",
    "    new_sample_freq = sample_freq / sub_freq\n",
    "    subsampled_signal = signal[:, ::sub_freq]\n",
    "    return new_sample_freq, subsampled_signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_metadata = {}\n",
    "\n",
    "data_path = 'data/real_datasets/eeg-motor-movementimagery-dataset-1.0.0/files'\n",
    "VOLOUNTEER_ID = 'S007'\n",
    "EXP_ID = '04'\n",
    "signal_path = f'{data_path}/{VOLOUNTEER_ID}/{VOLOUNTEER_ID}R{EXP_ID}.edf'\n",
    "\n",
    "signal, signal_headers, header = highlevel.read_edf(signal_path)\n",
    "signal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_metadata['volunteer_id'] = VOLOUNTEER_ID\n",
    "signal_metadata['exp_id'] = EXP_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Overall header: \", header)\n",
    "print(\"Number of channels: \", len(signal_headers))\n",
    "print(\"signal.shape: \", signal.shape)\n",
    "print(\"Names of the channels: \", [metadata['label'] for metadata in signal_headers])\n",
    "sample_freq = signal_headers[0]['sample_rate']\n",
    "print(\"The length of the signals in seconds is: \", signal.shape[1]//sample_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(signal_headers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = mne.io.read_raw_edf(signal_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(raw_data.ch_names)\n",
    "signal_metadata[\"channels\"] = raw_data.ch_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visual inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = header[\"annotations\"]\n",
    "print(annotations)\n",
    "gt_bkps = turn_time_cp_into_indices_cp(annotations, sampling_freq=sample_freq, last_ind=signal.shape[1])\n",
    "print(gt_bkps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_start = 0\n",
    "plot_end = 20000\n",
    "\n",
    "good_quality_channels = [\"Fc5\", \"Fc1\", \"Fc2\", \"Fc6\", \"C3\", \"Cz\", \"C4\", \"Cp5\", \"Cp1\", \"Cp2\", \"Cp6\", \"Fpz\", \"Af7\", \"Afz\", \"Af8\", \"F5\", \"F1\", \"F2\", \"F6\", \"Ft7\", \"T7\", \"T9\", \"Tp7\", \"P7\", \"P3\", \"Pz\", \"P4\", \"P8\", \"Po3\", \"Po4\", \"O1\", \"O2\"]\n",
    "good_quality_channels = [ch_name + '..' for ch_name in good_quality_channels]\n",
    "good_quality_channels = [ch_name[:4] for ch_name in good_quality_channels]\n",
    "\n",
    "# channels_to_show = mne.pick_channels_regexp(raw_data.ch_names, regexp=\"*\")\n",
    "channels_to_show = mne.pick_channels(raw_data.ch_names, include=good_quality_channels)\n",
    "print(\"Selected channel indices: \", channels_to_show)\n",
    "\n",
    "fig, axes = plot_selected_channels(channels_to_show, signal, signal_headers, plot_start, plot_end, sample_freq)\n",
    "axes = add_bkps_to_plot(axes, gt_bkps, color='k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_start = 0\n",
    "plot_end = 20000\n",
    "\n",
    "channels_to_show = mne.pick_channels(raw_data.ch_names, include=[], exclude=good_quality_channels)\n",
    "print(\"Selected channel indices: \", channels_to_show)\n",
    "\n",
    "fig, axes = plot_selected_channels(channels_to_show, signal, signal_headers, plot_start, plot_end, sample_freq)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Signal filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(20, 5))\n",
    "for i in range(signal.shape[0]):\n",
    "    f, Pxx_den = scipy.signal.welch(signal[i, :], sample_freq, nperseg=1024)\n",
    "    ax.semilogy(f, Pxx_den)\n",
    "ax.set_xlabel('frequency [Hz]')\n",
    "ax.set_ylabel('PSD [V**2/Hz]')\n",
    "ax.grid(visible=True, axis='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOW_PASS_FREQ = 0.5\n",
    "HIGH_PASS_FREQ = 30\n",
    "FILTER_ORDER = 5\n",
    "\n",
    "filtering_metada = {}\n",
    "filtering_metada[\"commit id\"] = my_ut.get_git_head_short_hash()\n",
    "filtering_metada[\"filtering function\"] = filter_signal.__name__\n",
    "filtering_metada[\"filter type\"] = \"bandpass butterworth\"\n",
    "filtering_metada[\"filter order\"] = FILTER_ORDER\n",
    "filtering_metada[\"low cutoff\"] = LOW_PASS_FREQ\n",
    "filtering_metada[\"high cutoff\"] = HIGH_PASS_FREQ\n",
    "signal_metadata[\"filtering\"] = filtering_metada\n",
    "\n",
    "filtered_signal = filter_signal(signal, filter_order=FILTER_ORDER, low_cutoff=LOW_PASS_FREQ, high_cutoff=HIGH_PASS_FREQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(20, 5))\n",
    "for i in range(filtered_signal.shape[0]):\n",
    "    f, Pxx_den = scipy.signal.welch(filtered_signal[i, :], sample_freq, nperseg=1024)\n",
    "    ax.semilogy(f, Pxx_den)\n",
    "ax.set_xlabel('frequency [Hz]')\n",
    "ax.set_ylabel('PSD [V**2/Hz]')\n",
    "ax.set_ylim(bottom=1e-3)\n",
    "ax.grid(visible=True, axis='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_start = 0\n",
    "plot_end = 20000\n",
    "\n",
    "good_quality_channels = [\"Fc5\", \"Fc1\", \"Fc2\", \"Fc6\", \"C3\", \"Cz\", \"C4\", \"Cp5\", \"Cp1\", \"Cp2\", \"Cp6\", \"Fpz\", \"Af7\", \"Afz\", \"Af8\", \"F5\", \"F1\", \"F2\", \"F6\", \"Ft7\", \"T7\", \"T9\", \"Tp7\", \"P7\", \"P3\", \"Pz\", \"P4\", \"P8\", \"Po3\", \"Po4\", \"O1\", \"O2\"]\n",
    "good_quality_channels = [ch_name + '..' for ch_name in good_quality_channels]\n",
    "good_quality_channels = [ch_name[:4] for ch_name in good_quality_channels]\n",
    "\n",
    "channels_to_show = mne.pick_channels(raw_data.ch_names, include=good_quality_channels)\n",
    "print(\"Selected channel indices: \", channels_to_show)\n",
    "\n",
    "fig, axes = plot_selected_channels(channels_to_show, filtered_signal, signal_headers, plot_start, plot_end, sample_freq)\n",
    "axes = add_bkps_to_plot(axes, gt_bkps, color='k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels_to_show = mne.pick_channels(raw_data.ch_names, include=[], exclude=good_quality_channels)\n",
    "print(\"Selected channel indices: \", channels_to_show)\n",
    "\n",
    "fig, axes = plot_selected_channels(channels_to_show, filtered_signal, signal_headers, plot_start, plot_end, sample_freq)\n",
    "axes = add_bkps_to_plot(axes, gt_bkps, color='k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Signal subsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBSAMPLING_FREQUENCY = 2\n",
    "\n",
    "new_subsample_freq, sub_sampled_signal = subsample_signal(filtered_signal, sub_freq=SUBSAMPLING_FREQUENCY, sample_freq=sample_freq)\n",
    "signal_metadata[\"subsampling frequency\"] = SUBSAMPLING_FREQUENCY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(20, 5))\n",
    "for i in range(sub_sampled_signal.shape[0]):\n",
    "    f, Pxx_den = scipy.signal.welch(sub_sampled_signal[i, :], new_subsample_freq, nperseg=1024)\n",
    "    ax.semilogy(f, Pxx_den)\n",
    "ax.set_xlabel('frequency [Hz]')\n",
    "ax.set_ylabel('PSD [V**2/Hz]')\n",
    "ax.set_ylim(bottom=1e-3)\n",
    "ax.grid(visible=True, axis='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = header[\"annotations\"]\n",
    "subsampled_gt_bkps = turn_time_cp_into_indices_cp(annotations, sampling_freq=new_subsample_freq, last_ind=sub_sampled_signal.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_start = 0\n",
    "plot_end = 10000\n",
    "\n",
    "good_quality_channels = [\"Fc5\", \"Fc1\", \"Fc2\", \"Fc6\", \"C3\", \"Cz\", \"C4\", \"Cp5\", \"Cp1\", \"Cp2\", \"Cp6\", \"Fpz\", \"Af7\", \"Afz\", \"Af8\", \"F5\", \"F1\", \"F2\", \"F6\", \"Ft7\", \"T7\", \"T9\", \"Tp7\", \"P7\", \"P3\", \"Pz\", \"P4\", \"P8\", \"Po3\", \"Po4\", \"O1\", \"O2\"]\n",
    "good_quality_channels = [ch_name + '..' for ch_name in good_quality_channels]\n",
    "good_quality_channels = [ch_name[:4] for ch_name in good_quality_channels]\n",
    "\n",
    "channels_to_show = mne.pick_channels(raw_data.ch_names, include=good_quality_channels)\n",
    "print(\"Selected channel indices: \", channels_to_show)\n",
    "\n",
    "fig, axes = plot_selected_channels(channels_to_show, sub_sampled_signal, signal_headers, plot_start, plot_end, new_subsample_freq)\n",
    "axes = add_bkps_to_plot(axes, subsampled_gt_bkps, color='k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Whole workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path = 'data/real_datasets/eeg-motor-movementimagery-dataset-1.0.0/files'\n",
    "data_path = 'data_1/real_data/physionet.org/files/eegmmidb/1.0.0'\n",
    "VOLOUNTEER_ID = 'S001'\n",
    "EXP_ID = '03'\n",
    "signal_path = f'{data_path}/{VOLOUNTEER_ID}/{VOLOUNTEER_ID}R{EXP_ID}.edf'\n",
    "signal, signal_headers, header = highlevel.read_edf(signal_path)\n",
    "sample_freq = signal_headers[0]['sample_rate']\n",
    "raw_data = mne.io.read_raw_edf(signal_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path = 'data/real_datasets/eeg-motor-movementimagery-dataset-1.0.0/files'\n",
    "data_path = 'data_1/real_data/physionet.org/files/eegmmidb/1.0.0'\n",
    "\n",
    "VOLOUNTEER_ID_LIST = ['S0' + str(i) for i in range(31, 51)]\n",
    "EXP_ID_LIST = ['03', '04', '05', '06', '07', '08', '09', '10', '11', '12', '13', '14']\n",
    "LOW_PASS_FREQ = 0.5\n",
    "HIGH_PASS_FREQ = 40\n",
    "FILTER_ORDER = 3\n",
    "SUBSAMPLING_FREQUENCY = 8\n",
    "# SAVING_DIR = \"data/real_datasets/eeg-motor-movementimagery-dataset-1.0.0/processed_signals\"\n",
    "SAVING_DIR = \"data_1/real_data/physionet.org/processed_signals\"\n",
    "\n",
    "subfolder = f\"filtered_{LOW_PASS_FREQ}-{HIGH_PASS_FREQ}_order_{FILTER_ORDER}_subsampled_{SUBSAMPLING_FREQUENCY}\"\n",
    "path = f\"{SAVING_DIR}/{subfolder}\"\n",
    "\n",
    "# logging\n",
    "signal_metadata = {}\n",
    "signal_metadata[\"channels\"] = raw_data.ch_names\n",
    "signal_metadata[\"sample freq\"] = sample_freq\n",
    "filtering_metada = {}\n",
    "filtering_metada[\"commit id\"] = my_ut.get_git_head_short_hash()\n",
    "filtering_metada[\"filtering function\"] = filter_signal.__name__\n",
    "filtering_metada[\"filter type\"] = \"bandpass butterworth\"\n",
    "filtering_metada[\"filter order\"] = FILTER_ORDER\n",
    "filtering_metada[\"low cutoff\"] = LOW_PASS_FREQ\n",
    "filtering_metada[\"high cutoff\"] = HIGH_PASS_FREQ\n",
    "signal_metadata[\"filtering\"] = filtering_metada\n",
    "signal_metadata[\"subsampling frequency\"] = SUBSAMPLING_FREQUENCY\n",
    "signal_metadata = my_ut.turn_all_list_of_dict_into_str(signal_metadata)\n",
    "# my_ut.create_parent_and_dump_json(path, name=f\"signals_metadata.json\", data=signal_metadata, indent=4)\n",
    "\n",
    "# signal processing\n",
    "for VOLOUNTEER_ID in VOLOUNTEER_ID_LIST: \n",
    "\n",
    "    save_dir = f'{path}/{VOLOUNTEER_ID}'\n",
    "    Path(save_dir).mkdir(parents=True, exist_ok=False)\n",
    "\n",
    "    for EXP_ID in EXP_ID_LIST:\n",
    "    \n",
    "        # data loading\n",
    "        signal_path = f'{data_path}/{VOLOUNTEER_ID}/{VOLOUNTEER_ID}R{EXP_ID}.edf'\n",
    "        signal, signal_headers, header = highlevel.read_edf(signal_path)\n",
    "\n",
    "        # data processing\n",
    "        filtered_signal = filter_signal(signal, filter_order=FILTER_ORDER, low_cutoff=LOW_PASS_FREQ, high_cutoff=HIGH_PASS_FREQ)\n",
    "        new_subsample_freq, sub_sampled_signal = subsample_signal(filtered_signal, sub_freq=SUBSAMPLING_FREQUENCY, sample_freq=sample_freq)\n",
    "        sub_sampled_signal = sub_sampled_signal.T\n",
    "        annotations = header[\"annotations\"]\n",
    "        subsampled_gt_bkps = turn_time_cp_into_indices_cp(annotations, sampling_freq=new_subsample_freq, last_ind=sub_sampled_signal.shape[1])\n",
    "\n",
    "        # data saving\n",
    "        NAME = f\"volunteer{VOLOUNTEER_ID}_exp{EXP_ID}\"\n",
    "        my_ut.save_signal_and_bkps(sub_sampled_signal, subsampled_gt_bkps, save_dir, NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a graph for the recording system\n",
    "\n",
    "The EEGs were recorded from 64 electrodes as per the international 10-10 system (excluding electrodes Nz, F9, F10, FT9, FT10, A1, A2, TP9, TP10, P9, and P10).\n",
    "\n",
    "**NOTE**: there exists a library building networkx graphs from EEG signals based on a given connectivity measure: [EEGGRaph](https://github.com/ufvceiec/EEGRAPH).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(5, 4))\n",
    "easycap_montage = mne.channels.make_standard_montage(\"easycap-M1\")\n",
    "montage_ch_names = easycap_montage.ch_names\n",
    "easycap_montage.plot(axes=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(easycap_montage.__dict__)\n",
    "print(type(easycap_montage.dig))\n",
    "print(easycap_montage.dig[3])\n",
    "print(easycap_montage.dig[3].__repr__())\n",
    "print(easycap_montage.dig[3].__repr__()[25:45])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uppercase_raw_data_ch_names = [ch_name.upper() for ch_name in raw_data.ch_names]\n",
    "temp_montage_ch_names = [ch_name + '..' for ch_name in montage_ch_names]\n",
    "upper_adataped_montage_ch_names = [ch_name[:4].upper() for ch_name in temp_montage_ch_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_channel_pos = easycap_montage.dig\n",
    "coord_per_channel_label = {}\n",
    "\n",
    "for ch_name, digpoint in zip(montage_ch_names, list_of_channel_pos[3:]):\n",
    "    # adapt the format of the ch names to the one provided by raw_data\n",
    "    ch_name = ch_name + '..'\n",
    "    ch_name = ch_name[:4]\n",
    "    if ch_name.upper() in uppercase_raw_data_ch_names:\n",
    "        # retrieve the corresponding coordinates\n",
    "        coords_str = digpoint.__repr__().split('(')[1].split(')')[0]\n",
    "        coords_str_list = coords_str.split(',')\n",
    "        coord_x, coord_y, coord_z = float(coords_str_list[0]), float(coords_str_list[1]), float(coords_str_list[2])\n",
    "        coord_per_channel_label[ch_name.upper()] = (coord_x, coord_y, coord_z)\n",
    "coord_per_channel_label['T9..'] = (-105, 0.0, -3.3)\n",
    "coord_per_channel_label['T10.'] = (105, 0.0, -3.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(uppercase_raw_data_ch_names)\n",
    "print(upper_adataped_montage_ch_names)\n",
    "print(coord_per_channel_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_name_per_signal_index_dict = {i: ch_name for i, ch_name in enumerate(uppercase_raw_data_ch_names)}\n",
    "signal_like_order_coords_per_ch_label = {ch_name_per_signal_index_dict[i]: coord_per_channel_label[ch_name_per_signal_index_dict[i]] for i in range(len(ch_name_per_signal_index_dict))}\n",
    "print(ch_name_per_signal_index_dict)\n",
    "print(signal_like_order_coords_per_ch_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signl_like_ordered_coords_arr = np.array([coords for coords in signal_like_order_coords_per_ch_label.values()])\n",
    "knn_graphs = knn_weights = KNN.from_array(signl_like_ordered_coords_arr, 4)\n",
    "G_directed = knn_weights.to_networkx()\n",
    "G = G_directed.to_undirected()\n",
    "node_labels = ch_name_per_signal_index_dict\n",
    "print(f\"The graph has {G.number_of_nodes()} nodes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "nx.draw_networkx(G, pos = signl_like_ordered_coords_arr[:, :2], ax=ax, labels=node_labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils as my_ut\n",
    "\n",
    "graph_name = 'KNN_4_64_ch_graph_mat_adj_order_signal_header.npy'\n",
    "my_ut.save_graph(G, f'data/real_datasets/eeg-motor-movementimagery-dataset-1.0.0/{graph_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_adj_mat = np.load(f'data/real_datasets/eeg-motor-movementimagery-dataset-1.0.0/{graph_name}', allow_pickle=False)\n",
    "G_saved = nx.from_numpy_array(saved_adj_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "nx.draw_networkx(G_saved, pos = signl_like_ordered_coords_arr[:, :2], ax=ax, labels=node_labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"data/real_datasets/eeg-motor-movementimagery-dataset-1.0.0/processed_signals/filtered_0.5-40_subsampled_2\"\n",
    "results_path = \"results_1/real_data/eeg-motor-movement/filtered_0.5-40_subsampled_2/S007_exp_04-05-06\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_path = f'{data_path}/volunteer{VOLOUNTEER_ID}_exp{EXP_ID}'\n",
    "to_plot_signal = np.load(f\"{signal_path}_signal.npy\", allow_pickle=False)\n",
    "to_plot_signal_metadata = my_ut.open_json(f\"{signal_path}_metadata.json\")\n",
    "final_sample_freq = sample_freq / to_plot_signal_metadata[\"subsampling frequency\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statio_pred = my_ut.open_json(f\"{results_path}/statio_pred.json\")[str(EXP_ID)]\n",
    "pred_bkps = my_ut.turn_str_of_list_into_list_of_int(statio_pred[\"pred\"])\n",
    "gt_bkps = my_ut.turn_str_of_list_into_list_of_int(statio_pred[\"gt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_start = 0\n",
    "plot_end = 10000\n",
    "\n",
    "good_quality_channels = [\"Fc5\", \"Fc1\", \"Fc2\", \"Fc6\", \"C3\", \"Cz\", \"C4\", \"Cp5\", \"Cp1\", \"Cp2\", \"Cp6\", \"Fpz\", \"Af7\", \"Afz\", \"Af8\", \"F5\", \"F1\", \"F2\", \"F6\", \"Ft7\", \"T7\", \"T9\", \"Tp7\", \"P7\", \"P3\", \"Pz\", \"P4\", \"P8\", \"Po3\", \"Po4\", \"O1\", \"O2\"]\n",
    "good_quality_channels = [ch_name + '..' for ch_name in good_quality_channels]\n",
    "good_quality_channels = [ch_name[:4] for ch_name in good_quality_channels]\n",
    "\n",
    "# channels_to_show = mne.pick_channels_regexp(raw_data.ch_names, regexp=\"*\")\n",
    "channels_to_show = mne.pick_channels(raw_data.ch_names, include=good_quality_channels)\n",
    "print(\"Selected channel indices: \", channels_to_show)\n",
    "\n",
    "fig, axes = plot_selected_channels(channels_to_show, to_plot_signal, signal_headers, plot_start, plot_end, final_sample_freq)\n",
    "axes = add_bkps_to_plot(axes, gt_bkps, color='g')\n",
    "axes = add_bkps_to_plot(axes, pred_bkps, color='darkorange')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_start = 0\n",
    "plot_end = 10000\n",
    "\n",
    "channels_to_show = mne.pick_channels(raw_data.ch_names, include=[], exclude=good_quality_channels)\n",
    "print(\"Selected channel indices: \", channels_to_show)\n",
    "\n",
    "fig, axes = plot_selected_channels(channels_to_show, to_plot_signal, signal_headers, plot_start, plot_end, final_sample_freq)\n",
    "axes = add_bkps_to_plot(axes, gt_bkps, color='g')\n",
    "axes = add_bkps_to_plot(axes, pred_bkps, color='darkorange')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

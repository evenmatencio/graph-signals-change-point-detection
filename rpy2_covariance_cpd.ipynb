{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test on ```rpy2```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import utils as my_ut\n",
    "import result_related as my_res\n",
    "\n",
    "from math import floor\n",
    "from datetime import datetime\n",
    "from typing import List\n",
    "from tqdm import tqdm\n",
    "from sklearn.covariance import log_likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ```rpy2``` utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rpy2\n",
    "import rpy2.robjects as robjects\n",
    "\n",
    "## To aid in printing HTML in notebooks\n",
    "import rpy2.ipython.html\n",
    "rpy2.ipython.html.init_printing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rpy2.robjects.packages import importr\n",
    "\n",
    "r_base = importr('base')\n",
    "r_utils = importr('utils')\n",
    "r_cp = importr('changepoints')\n",
    "r_covcp = importr('covcp')\n",
    "r_mass = importr('MASS')\n",
    "r_domc = importr('doMC')\n",
    "r_parallel = importr('parallel')\n",
    "r_RcppCNPy = importr('RcppCNPy')\n",
    "r_reticulate = importr('reticulate')\n",
    "r_glasso = importr('glasso')\n",
    "\n",
    "rprint = robjects.globalenv.find(\"print\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nested_named_element_from_R_list(obj, named_elem:str):\n",
    "    nested_names_list = named_elem.split('$')\n",
    "    target_obj = obj\n",
    "    for name in nested_names_list:\n",
    "        if name.isdigit():\n",
    "            target_obj = target_obj.rx2(int(name))\n",
    "        else:\n",
    "            target_obj = target_obj.rx2(name)\n",
    "    return target_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def turn_r_bool_in_py_bool(r_bool):\n",
    "    str_r_bool = str(r_bool.rx2(1))[4:9]\n",
    "    return not str_r_bool == 'FALSE'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sandbox on CPD algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments with ```glasso```\n",
    "\n",
    "Je peux bien travailler avec la fonction loglikelihood de scikit learn, quitte à la ré-implémenter de mon côté (bien faire attention à ce que les signes soient les bons, qu'on ne maximise pas à l'envers). Ce qu'il reste donc à faire c'est de faire les calculs de matrices de précision avec la librairie R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_signal_path = 'data_1/.temp/left_sub_signal.npy'\n",
    "r_signal = r_RcppCNPy.npyLoad(some_signal_path)\n",
    "print(r_base.dim(r_signal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pen_coef = r_covcp.chooseRho(r_signal)\n",
    "emp_cov = r_covcp.Cov(r_signal)\n",
    "glasso_invcov_mat = r_glasso.glasso(s=emp_cov, rho=pen_coef).rx2('wi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def glasso_cost_func(start, end, signal, pen_mult_coef):\n",
    "    # extracting the target subsignal in R\n",
    "    sub_signal = signal[start:end, :]\n",
    "    np.save(\"data_1/.temp/glasso_sub_signal_1.npy\", sub_signal)\n",
    "    r_subsignal = r_RcppCNPy.npyLoad(\"data_1/.temp/glasso_sub_signal_1.npy\")\n",
    "    # applying the R implementation of Graphical Lasso\n",
    "    raw_pen_coef = r_covcp.chooseRho(r_subsignal)\n",
    "    pen_coef = r_base.c(pen_mult_coef * raw_pen_coef[0])\n",
    "    r_emp_cov = r_covcp.Cov(r_subsignal)\n",
    "    r_glasso_obj = r_glasso.glasso(s=r_emp_cov, rho=pen_coef, maxit=10)\n",
    "    r_glasso_preci_mat = r_glasso_obj.rx2('wi')\n",
    "    # computing the cost function\n",
    "    glasso_preci_mat = np.asarray(r_glasso_preci_mat)\n",
    "    emp_cov = np.asarray(r_emp_cov)\n",
    "    cost_func_val = - log_likelihood(emp_cov, glasso_preci_mat)\n",
    "    return cost_func_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rglasso_cpd_dynprog(n_bkps:int, min_size:int, signal, pen_mult_coef):\n",
    "    # path_mat[n, K] avec n --> [y_0, ... y_{n-1}] (very important to understand indexing) , K : n_bkps\n",
    "    # sum_of_cost_mat[n, K]: best cost for signal until sample n with K bkps\n",
    "\n",
    "    # initialization \n",
    "    n_samples = signal.shape[0]\n",
    "    path_mat = np.empty((n_samples+1, n_bkps+1), dtype=np.int32)\n",
    "    path_mat[:, 0] = 0\n",
    "    path_mat[0, :] = -1\n",
    "    sum_of_cost_mat = np.full((n_samples+1, n_bkps+1),  fill_value=np.inf, dtype=np.float64)\n",
    "    sum_of_cost_mat[0, :] = 0\n",
    "\n",
    "    # pre-computation, to optimize jit processing\n",
    "    statio_segment_cost = np.full((n_samples+1, n_samples+1), fill_value=np.inf, dtype=np.float64)\n",
    "    for start in tqdm(range(0, n_samples-min_size+1), desc='Looping over the segments start'):\n",
    "        for end in range(start+min_size, n_samples+1):\n",
    "            statio_segment_cost[start, end] = glasso_cost_func(start, end, signal, pen_mult_coef)\n",
    "\n",
    "    # forward computation\n",
    "    for end in range(min_size, n_samples+1):\n",
    "        sum_of_cost_mat[end, 0] = statio_segment_cost[0, end]\n",
    "        # consistent because our cost functions compute the costs over [start, end[\n",
    "        max_admissible_n_bkp = floor(end/min_size) - 1\n",
    "        for k_bkps in range(1, min(max_admissible_n_bkp+1, n_bkps+1)):\n",
    "            soc_optim = np.inf\n",
    "            soc_argmin = -1\n",
    "            for mid in range(min_size*k_bkps, end - min_size + 1):\n",
    "                soc = sum_of_cost_mat[mid, k_bkps-1] + statio_segment_cost[mid, end]\n",
    "                if soc < soc_optim:\n",
    "                    soc_argmin = mid\n",
    "                    soc_optim = soc\n",
    "            sum_of_cost_mat[end, k_bkps] = soc_optim\n",
    "            path_mat[end, k_bkps] = soc_argmin\n",
    "\n",
    "    # backtracking\n",
    "    bkps = np.full((n_bkps+1), fill_value=n_samples)\n",
    "    for k_bkps in range(n_bkps, 0, -1):\n",
    "        bkps[k_bkps-1] = path_mat[bkps[k_bkps], k_bkps]\n",
    "    \n",
    "    return bkps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_r_glasso_cpd_algo(signal, gt_bkps: List[int], rglasso_results: dict, exp_id: int, pen_mult_coef: float):\n",
    "    # running CPD algorithm\n",
    "    t1 = time.perf_counter()\n",
    "    glasso_bkps = rglasso_cpd_dynprog(n_bkps=len(gt_bkps)-1, min_size=signal.shape[1], signal=signal, pen_mult_coef=pen_mult_coef)\n",
    "    t2 = time.perf_counter()\n",
    "    glasso_bkps.sort()\n",
    "    glasso_bkps = [int(bkp) for bkp in glasso_bkps]\n",
    "    # logging\n",
    "    rglasso_results[exp_id] = {}\n",
    "    rglasso_results[exp_id][\"time\"] = round(t2 - t1, ndigits=3)\n",
    "    rglasso_results[exp_id][\"pred\"] = glasso_bkps\n",
    "    rglasso_results[exp_id][\"gt\"] = gt_bkps\n",
    "    rglasso_results[exp_id][\"n_bkps\"] = len(gt_bkps)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_r_glasso_cpd_algo_and_store(signal, gt_bkps: List[int], json_path: str, exp_id: str, pen_mult_coef: float):\n",
    "    # running CPD algorithm\n",
    "    t1 = time.perf_counter()\n",
    "    glasso_bkps = rglasso_cpd_dynprog(n_bkps=len(gt_bkps)-1, min_size=signal.shape[1], signal=signal, pen_mult_coef=pen_mult_coef)\n",
    "    t2 = time.perf_counter()\n",
    "    glasso_bkps.sort()\n",
    "    glasso_bkps = [int(bkp) for bkp in glasso_bkps]\n",
    "    # logging\n",
    "    res = {}\n",
    "    res[\"time\"] = round(t2 - t1, ndigits=3)\n",
    "    res[\"pred\"] = glasso_bkps\n",
    "    res[\"gt\"] = gt_bkps\n",
    "    res[\"n_bkps\"] = len(gt_bkps)-1\n",
    "    my_ut.load_and_write_json(json_path, exp_id, my_ut.turn_all_list_of_dict_into_str(res), indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SYNTHETIC DATA ADAPTED\n",
    "##########################\n",
    "\n",
    "NAME =  \"ER_20_nodes_deg_10_bandwidth_0.4\"\n",
    "GRAPH_PATH = \"data_1/synthetic_data/graphs/clean_ER_with_bandwidth\"\n",
    "GRAPH_NAME =  NAME  #+ f\"_edge_prop_{EDGE_PROP}\" #\"exp_geo_20_nodes_av_deg_10\" #\"ER_20_nodes_deg_10_bandwidth_0.4_edge_prop_0.05\" \n",
    "SIGNAL_PATH = \"data_1/synthetic_data/signal/within_hyp/SNR_20_graph_lasso_calibration\" #\"data_1/signal/within_hyp/SNR_20_varying_segment_length\"\n",
    "MAX_ID_SUBSET = 12\n",
    "RESULT_DIR = \"results_1/synthetic/within_hypothesis_noisy/glasso_experiments/SNR_20_large_x0.4_1000_samples\"\n",
    "LASSO_ALPHA = \"from_covcp_paper\"\n",
    "MIN_SEGMENT_LENGTH_COEF = 0.4\n",
    "SNR = 20\n",
    "BKPS_GAP_CONSTRAINT = \"large\"\n",
    "N_BKPS = 4\n",
    "# NB_BREAKDOWN = 6\n",
    "# BREAKDOWN_LENGTH_LIST = [50, 100, 150, 200, 250, 300, 350, 400, 450, 500]\n",
    "# SNR_LIST = [-5, 5, 15]\n",
    "# SEG_LENGTH_COEF_LIST = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "# EDGE_PROP_MODIF_LIST = [0.03, 0.05, 0.08, 0.1, 0.15, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "OTHER_GRAPH_SEED = 1\n",
    "PEN_MULT_COEF_LIST = [2, 4]\n",
    "\n",
    "now = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "# logging\n",
    "graph_path = os.path.join(GRAPH_PATH, GRAPH_NAME)\n",
    "graph_metadata = my_ut.open_json(f\"{graph_path}/00_graphs_metadata.json\")\n",
    "seg_length_hyp = \"minimal\"\n",
    "graph_rng = np.random.default_rng(OTHER_GRAPH_SEED)\n",
    "\n",
    "for PEN_COEF in PEN_MULT_COEF_LIST:\n",
    "\n",
    "    print(f\"\\n\\n \\t Working with multiplicative coefficient: {PEN_COEF} \\n\")\n",
    "    \n",
    "    # SIGNAL_NAME = f\"{BKPS_GAP_CONSTRAINT}_x{MIN_SEGMENT_LENGTH_COEF}_SNR_{round(SNR, 4)}\" + \"_\" + GRAPH_NAME \n",
    "    SIGNAL_NAME = f\"{N_BKPS}_bkps_{BKPS_GAP_CONSTRAINT}_x{MIN_SEGMENT_LENGTH_COEF}_SNR_{round(SNR, 4)}_1000_samples\" + \"_\" + GRAPH_NAME     #  _NBbd_{NB_BREAKDOWN}_bklength_{BREAKDOWN_LENGTH}\"    #\n",
    "    signal_path = os.path.join(SIGNAL_PATH, SIGNAL_NAME)\n",
    "    signal_metadata = my_ut.open_json(f\"{signal_path}/00_signal_metadata.json\")\n",
    "    \n",
    "    RESULT_NAME = f\"pen_coef_gridsearch_{LASSO_ALPHA}\"\n",
    "    final_name = SIGNAL_NAME + \"_\" + RESULT_NAME\n",
    "    results_dir = os.path.join(RESULT_DIR, final_name)\n",
    "\n",
    "    exp_desc = \"Test of the graphical Lasso cost function: grid seach over the L1 penalty coefficient. Its value is fixed according to the fromula from the covcp paper and a multiplicative coefficient.\"\n",
    "    experiment_metadata = {\"datetime\": now, \"description\": exp_desc, \"commit hash\": my_ut.get_git_head_short_hash(), \"graph folder\": graph_path, \"graph metadata\": graph_metadata, \"signal folder\": SIGNAL_PATH + '/' + SIGNAL_NAME, \"signal metadata\": signal_metadata, \"min segment length hypothesis\": seg_length_hyp, \"max id experiment subset\": MAX_ID_SUBSET, \"lasso penalty coefficient\": LASSO_ALPHA}\n",
    "\n",
    "    # output formatting\n",
    "    # statio_results = {}\n",
    "    # normal_results = {}\n",
    "    lasso_results = {}\n",
    "    name = f\"lasso_pred_pencoefmult_{PEN_COEF}.json\"\n",
    "    json_path = os.path.join(results_dir, name)\n",
    "    my_ut.create_parent_and_dump_json(results_dir, name, my_ut.turn_all_list_of_dict_into_str(lasso_results), indent=4)\n",
    "\n",
    "    # running CPD algorithms\n",
    "    # for exp_id in tqdm(range(MAX_ID_SUBSET), desc='Running experiment...'):\n",
    "    for exp_id in range(MAX_ID_SUBSET):\n",
    "        exp_id = str(exp_id)\n",
    "        G, signal, gt_bkps, min_size = my_ut.load_data(graph_path, signal_path, exp_id, seg_length_hyp)\n",
    "        exp_res = run_r_glasso_cpd_algo_and_store(signal, gt_bkps, json_path, exp_id, PEN_COEF)\n",
    "\n",
    "        # run_r_glasso_cpd_algo(signal, gt_bkps, lasso_results, exp_id, PEN_COEF)\n",
    "\n",
    "    my_ut.create_parent_and_dump_json(results_dir, F\"lasso_pred_pencoefmult_{PEN_COEF}.json\", my_ut.turn_all_list_of_dict_into_str(lasso_results), indent=4)\n",
    "my_ut.create_parent_and_dump_json(results_dir, \"experiment_metadata.json\", my_ut.turn_all_list_of_dict_into_str(experiment_metadata), indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### REAL DATA ADAPTED\n",
    "##########################\n",
    "\n",
    "# NAME =  \"ER_20_nodes_deg_10_bandwidth_0.4\"\n",
    "GRAPH_PATH = \"data/real_data/test_filtered_0.5-40_order_3_subsampled_8\"\n",
    "GRAPH_NAME =  \"KNN_4_64_ch_graph_mat_adj_order_signal_header\"\n",
    "SIGNAL_PATH = \"data/real_data/test_filtered_0.5-40_order_3_subsampled_8\" \n",
    "RESULT_DIR = \"results_1/real_data/test/filtered_0.5-40_order_3_subsampled_8\"\n",
    "LASSO_ALPHA = \"from_covcp_paper\"\n",
    "seg_length_hyp = \"minimal\"\n",
    "\n",
    "# GRAPH LASSO METHOD\n",
    "PEN_MULT_COEF_LIST = [4]\n",
    "\n",
    "# R COVCP METHOD\n",
    "R_COVCP_SEED = 42\n",
    "NB_CORES = 2\n",
    "LEVEL_ALPHA = 0.3\n",
    "STABLE_SET_LENGTH = 80\n",
    "WINDOWS_SIZE = [80]\n",
    "\n",
    "\n",
    "now = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "# logging\n",
    "graph_path = os.path.join(GRAPH_PATH, GRAPH_NAME)\n",
    "# graph_metadata = my_ut.open_json(f\"{graph_path}/00_graphs_metadata.json\")\n",
    "# graph_rng = np.random.default_rng(OTHER_GRAPH_SEED)\n",
    "\n",
    "for PEN_COEF in PEN_MULT_COEF_LIST:\n",
    "\n",
    "    print(f\"\\n\\n \\t Working with multiplicative coefficient: {PEN_COEF} \\n\")\n",
    "    \n",
    "    # SIGNAL_NAME = f\"{BKPS_GAP_CONSTRAINT}_x{MIN_SEGMENT_LENGTH_COEF}_SNR_{round(SNR, 4)}\" + \"_\" + GRAPH_NAME \n",
    "    SIGNAL_NAME = \"volunteerS007_exp04\"\n",
    "    signal_path = os.path.join(SIGNAL_PATH, SIGNAL_NAME)\n",
    "    # signal_metadata = my_ut.open_json(f\"{signal_path}/00_signal_metadata.json\")\n",
    "    \n",
    "    RESULT_NAME = f\"running_time_test_with_mult_coef_{PEN_COEF}_{LASSO_ALPHA}\"\n",
    "    final_name = SIGNAL_NAME + \"_\" + RESULT_NAME\n",
    "    results_dir = os.path.join(RESULT_DIR, final_name)\n",
    "\n",
    "    exp_desc = \"Test of the graphical Lasso cost function.\"\n",
    "    experiment_metadata = {\"datetime\": now, \"description\": exp_desc, \"commit hash\": my_ut.get_git_head_short_hash(), \"graph folder\": \"no graph\", \"graph metadata\": \"no graph\", \"signal folder\": SIGNAL_PATH + '/' + SIGNAL_NAME}\n",
    "\n",
    "    # output formatting\n",
    "    # statio_results = {}\n",
    "    # normal_results = {}\n",
    "    lasso_results = {}\n",
    "    covcp_results = {}\n",
    "\n",
    "    # running CPD algorithms\n",
    "    # for exp_id in tqdm(range(MAX_ID_SUBSET), desc='Running experiment...'):\n",
    "    # G, signal, gt_bkps, min_size = my_ut.load_data(graph_path, signal_path, exp_id, seg_length_hyp)\n",
    "    # signal = np.load(f\"{signal_path}_signal.npy\", allow_pickle=False).T\n",
    "    # bkps = my_ut.open_json(f\"{signal_path}_bkps.json\")\n",
    "    # run_r_glasso_cpd_algo(signal, gt_bkps, lasso_results, exp_id, PEN_COEF)\n",
    "    r_signal = r_base.t(r_RcppCNPy.npyLoad(signal_path + '_signal.npy'))\n",
    "    gt_bkps = my_ut.open_json(signal_path + '_bkps.json')\n",
    "    min_size = 64\n",
    "    run_r_covcp_algo(r_signal, gt_bkps, covcp_results, STABLE_SET_LENGTH, min_size, WINDOWS_SIZE, LEVEL_ALPHA, 0)\n",
    "\n",
    "    my_ut.create_parent_and_dump_json(results_dir, F\"r_covcp_level_{LEVEL_ALPHA}_stableset_{STABLE_SET_LENGTH}_adapted_windowsize_{WINDOWS_SIZE[0]}_pred.json\", my_ut.turn_all_list_of_dict_into_str(covcp_results), indent=4)\n",
    "    # my_ut.create_parent_and_dump_json(results_dir, F\"lasso_pred_pencoefmult_{PEN_COEF}.json\", my_ut.turn_all_list_of_dict_into_str(lasso_results), indent=4)\n",
    "\n",
    "# my_ut.create_parent_and_dump_json(results_dir, \"experiment_metadata.json\", my_ut.turn_all_list_of_dict_into_str(experiment_metadata), indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SYNTHETIC DATA ADAPTED\n",
    "###########################\n",
    "\n",
    "PRECI_RECALL_MARGIN = 5\n",
    "res_folder_root = \"results_1/synthetic/within_hypothesis_noisy/glasso_experiments/SNR_20_large_x0.4_1000_samples/4_bkps_large_x0.4_SNR_20_1000_samples_ER_20_nodes_deg_10_bandwidth_0.4_pen_coef_gridsearch_from_covcp_paper\"\n",
    "file_names = os.listdir(res_folder_root)\n",
    "# PRED_FOLDER = [os.path.join(res_folder_root, file_name) for file_name in file_names]  #'.txt' not in file_name]\n",
    "PRED_FOLDER = [res_folder_root]\n",
    "\n",
    "# pencoef_mult_list =  [1, 2, 4]\n",
    "# pencoef_mult_list =  [0.6, 0.8, 1.0, 1.2, 1.4, 6, 8, 10, 12, 14, 20, 30]\n",
    "# pencoef_mult_list =  [1, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 25]\n",
    "# pencoef_mult_list =  [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "pencoef_mult_list =  [0.001, 0.5, 1, 5, 10, 20, 100]\n",
    "\n",
    "for pred_dir in PRED_FOLDER:\n",
    "\n",
    "    # fetching predictions\n",
    "    data_stats = my_ut.open_json(f\"{pred_dir}/experiment_metadata.json\")\n",
    "\n",
    "    # output formatting\n",
    "    metrics_dic = {}\n",
    "    metrics_dic[\"pred_path\"] = pred_dir\n",
    "    metrics_dic[\"hyper-parameters\"] = data_stats\n",
    "    metrics_dic[\"hyper-parameters\"][\"metrics_margin\"] = PRECI_RECALL_MARGIN\n",
    "    full_results = {}\n",
    "\n",
    "    for pencoefmult in pencoef_mult_list:\n",
    "\n",
    "        lasso_pencoef_pred_dic = my_ut.open_json(f\"{pred_dir}/lasso_pred_pencoefmult_{pencoefmult}.json\")\n",
    "        pencoef_glasso_results = {\"recall\": {'raw': []}, \"precision\": {'raw': []}, \"f1_score\": {'raw': []}, \"hausdorff\": {'raw': []}, \"assignement_cost\": {'raw': []}, \"time\": {\"raw\": []}}\n",
    "\n",
    "        for exp_id in lasso_pencoef_pred_dic.keys():\n",
    "            # compute metrics\n",
    "            lasso_pred_bkps = my_ut.turn_str_of_list_into_list_of_int(lasso_pencoef_pred_dic[exp_id][\"pred\"])\n",
    "            gt_bkps = my_ut.turn_str_of_list_into_list_of_int(lasso_pencoef_pred_dic[exp_id][\"gt\"])\n",
    "            my_res.compute_and_update_metrics(gt_bkps, lasso_pred_bkps, pencoef_glasso_results, PRECI_RECALL_MARGIN)\n",
    "            my_res.compute_assignement_cost(gt_bkps, lasso_pred_bkps, pencoef_glasso_results)\n",
    "            pencoef_glasso_results[\"time\"][\"raw\"].append(lasso_pencoef_pred_dic[exp_id][\"time\"])\n",
    "\n",
    "        full_results[pencoefmult] = pencoef_glasso_results\n",
    "        \n",
    "    # results post-precessing and saving\n",
    "    full_results = my_res.compute_and_add_stat_on_metrics(full_results)\n",
    "    full_results[\"metadata\"] = metrics_dic\n",
    "    full_results = my_ut.turn_all_list_of_dict_into_str(full_results)\n",
    "    my_ut.create_parent_and_dump_json(pred_dir, f'metrics_{PRECI_RECALL_MARGIN}.json', full_results, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments with ```akopich/covcp```\n",
    "\n",
    "Comprehénsion de la méthode : \n",
    "\n",
    "- un cpd est déclaré si pour une des taille de fenêtres on atteint, pour un des points centraux (de la fenêtre) une valeur de la statistique supérieure à la valeur critique (le seuil) calculé pour cette taille de fenêtre. \n",
    "- a priori les valeurs critiques sont calculées grâce au bootstrap ('data-driven approach')\n",
    "- pour confirmer mon intuition sur la compréhension de la méthode :\n",
    "    - aller voir dans la résolution de l'algo si je trouve d'où viennent les \"critical values\" pour confirmer qu'elles sont bien calculées grâce au bootstrap\n",
    "    - a priori dans mon expérience on ne détecte le cp que pour la plus grande taillede fenêtre (parce que meilleure estimation ?)\n",
    "        - aller voir comment évoluent les valeurs de la critical value en fonction de la taille de la fenêtre\n",
    "        --> **les valeurs critiques diminuent systématiquement avec la taille des fenêtres considérées**\n",
    "        - éventuellement faire des plot pour assess tout ça, et comprendre un peu mieux grâce à l'article comment fonctionne le bootstrap\n",
    "    - concernant le niveau alpha :\n",
    "        - comment influence les résultats : revenir à la définition pour voir si cohérent\n",
    "        - voir si intervient bien dans le bootstrap au moment du calcul des valeurs critiques : censé les diminuer ou augmenter\n",
    "    - comment influence la taille de l'échantillon 'stable' pour le bootstrap ?\n",
    "        --> **jusque là, les expériences réalisées montrent que lorsqu'on diminue la taille du stableset, on diminue aussi les valeurs critiques**\n",
    "    - comment influence la taille des segments de stationarité ?\n",
    "\n",
    "A faire en code : \n",
    "\n",
    "- transformer les données python en données R (voir doc rpy2 sur le paragraphe associé)\n",
    "- implémenter la détection de plusieurs ruptures (relire ce qu'ils disent dans l'article à ce sujet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_covcp_localization(covcp_results, window_sizes):\n",
    "    # check if there is actually a cp to localize\n",
    "    is_there_cp = r_covcp.isRejected(covcp_results)\n",
    "    if not is_there_cp:\n",
    "        return None\n",
    "    # if so, return the smallest window in which the cp can be localized\n",
    "    ciritical_values = covcp_results.rx2('criticalValue')\n",
    "    for i, window_size in enumerate(window_sizes):\n",
    "        window_stat_results = get_nested_named_element_from_R_list(covcp_results, f'statistics$window2statistics${i+1}')\n",
    "        max_stat = window_stat_results.rx2('statistics')[0]\n",
    "        if max_stat > ciritical_values[i]:\n",
    "            central_points = window_stat_results.rx2('centralPoints')\n",
    "            stat_values_arr = np.asarray(window_stat_results.rx2('distances'))\n",
    "            stats_argmx = int(np.argmax(stat_values_arr))\n",
    "            central_point_argmax = central_points[stats_argmx]\n",
    "            return central_point_argmax, (central_point_argmax - window_size, central_point_argmax + window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_r_left_subsignal(signal: np.ndarray, split_id):\n",
    "    left_sub_signal_arr = np.copy(signal)[:split_id, :]\n",
    "    np.save(\"data_1/.temp/left_sub_signal.npy\", left_sub_signal_arr)\n",
    "    r_left_subsignal = r_RcppCNPy.npyLoad(\"data_1/.temp/left_sub_signal.npy\")\n",
    "    return r_left_subsignal\n",
    "\n",
    "\n",
    "def get_r_right_subsignal(signal: np.ndarray, split_id):\n",
    "    right_sub_signal_arr = np.copy(signal)[split_id:, :]\n",
    "    np.save(\"data_1/.temp/right_sub_signal.npy\", right_sub_signal_arr)\n",
    "    r_right_subsignal = r_RcppCNPy.npyLoad(\"data_1/.temp/right_sub_signal.npy\")\n",
    "    return r_right_subsignal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_multiple_bkps(n_bkps, signal, stable_set_length, min_seg_length, window_sizes, alpha, bkps, left_offset=0):\n",
    "    bootstrap_stableSet = r_base.seq(1, stable_set_length)\n",
    "    print('Looking for a cp')\n",
    "    cov_cp_stat_test = r_covcp.covTest(window_sizes, alpha, signal, r_covcp.noPattern, r_covcp.infNorm, bootstrap_stableSet)\n",
    "    cov_cp_loc = get_covcp_localization(cov_cp_stat_test, window_sizes)\n",
    "    if cov_cp_loc is None:\n",
    "        return bkps\n",
    "    else:\n",
    "        # add current bkp\n",
    "        cp, _ = cov_cp_loc\n",
    "        bkps.append(left_offset + cp)\n",
    "        if len(bkps) < n_bkps:\n",
    "            print(f\"Detected cp: {cp}\")\n",
    "            # apply to left and right subsignal\n",
    "            signal_arr = np.copy(np.asarray(signal))\n",
    "            if cp - 1 > 2*min_seg_length:\n",
    "                r_left_subsignal = get_r_left_subsignal(signal_arr, cp-1)\n",
    "                # adapting window size\n",
    "                if r_base.dim(r_left_subsignal)[0] < 2*window_sizes[0]:\n",
    "                    window_sizes = [(r_base.dim(r_left_subsignal)[0])//2 - 1]\n",
    "                print(f\"Left window_size: {window_sizes}\")\n",
    "                detect_multiple_bkps(n_bkps, r_left_subsignal, stable_set_length, min_seg_length, window_sizes, alpha, bkps, left_offset=left_offset)\n",
    "            if signal_arr.shape[0] - cp + 1 > 2*min_seg_length:\n",
    "                r_right_subsignal = get_r_right_subsignal(signal_arr, cp-1)\n",
    "                # adapting window size\n",
    "                if r_base.dim(r_right_subsignal)[0] < 2*window_sizes[0]:\n",
    "                    window_sizes = [(r_base.dim(r_right_subsignal)[0])//2 - 1]\n",
    "                print(f\"Right window_size: {window_sizes}\")\n",
    "                detect_multiple_bkps(n_bkps, r_right_subsignal, stable_set_length, min_seg_length, window_sizes, alpha, bkps, left_offset=left_offset+cp)\n",
    "        return bkps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_r_covcp_algo(r_signal, gt_bkps: List[int], covcp_results: dict, stable_set_length:int, min_seg_length:int, window_sizes, alpha, exp_id):\n",
    "    # running CPD algorithm\n",
    "    t1 = time.perf_counter()\n",
    "    covcp_bkps = detect_multiple_bkps(n_bkps=len(gt_bkps)-1, signal=r_signal, stable_set_length=stable_set_length, min_seg_length=min_seg_length, window_sizes=window_sizes, alpha=alpha, bkps=[])\n",
    "    t2 = time.perf_counter()\n",
    "    covcp_bkps.sort()\n",
    "    covcp_bkps = [int(bkp) for bkp in covcp_bkps] + [r_base.dim(r_signal)[0]]\n",
    "    # logging\n",
    "    covcp_results[exp_id] = {}\n",
    "    covcp_results[exp_id][\"time\"] = round(t2 - t1, ndigits=3)\n",
    "    covcp_results[exp_id][\"pred\"] = covcp_bkps\n",
    "    covcp_results[exp_id][\"gt\"] = gt_bkps\n",
    "    covcp_results[exp_id][\"n_bkps\"] = len(gt_bkps)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Signal generation\n",
    "p = 20\n",
    "n_samples_1 = 400\n",
    "n_samples_2 = 400\n",
    "n_samples = n_samples_1 + n_samples_2\n",
    "A1 = r_cp.gen_cov_mat(p, 10, \"equal\")\n",
    "A2 = r_cp.gen_cov_mat(p, 10, \"diagonal\")\n",
    "X = r_base.rbind(r_mass.mvrnorm(n = n_samples_1, mu = r_base.rep(0, p), Sigma = A1),\n",
    "    r_mass.mvrnorm(n = n_samples_2, mu = r_base.rep(0, p), Sigma = A2)\n",
    ")\n",
    "print(r_base.dim(X)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Signal generation\n",
    "p = 20\n",
    "n_samples_1 = 400\n",
    "n_samples_2 = 400\n",
    "n_samples_3 = 200\n",
    "n_samples = n_samples_1 + n_samples_2 + n_samples_3\n",
    "A1 = r_cp.gen_cov_mat(p, 1, \"equal\")\n",
    "A2 = r_cp.gen_cov_mat(p, 1, \"diagonal\")\n",
    "A3 = r_cp.gen_cov_mat(p, 1, \"equal\")\n",
    "X_mult = r_base.rbind(r_mass.mvrnorm(n = n_samples_1, mu = r_base.rep(0, p), Sigma = A1),\n",
    "    r_mass.mvrnorm(n = n_samples_2, mu = r_base.rep(0, p), Sigma = A2), \n",
    "    r_mass.mvrnorm(n = n_samples_3, mu = r_base.rep(0, p), Sigma = A3)\n",
    ")\n",
    "print(r_base.dim(X_mult))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "windows = r_base.c(50) \n",
    "alpha = 0.3\n",
    "len_stable_set = 190"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_domc.registerDoMC(cores = 5)\n",
    "r_base.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bkps = detect_multiple_bkps(n_bkps=2, signal=X_mult, min_seg_length=len_stable_set, window_sizes=windows, alpha=alpha, bkps=[]) \n",
    "bkps.sort()\n",
    "print(bkps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_signal_to_load = \"data_1/signal/within_hyp/noisy_varying_segment_length/large_x1.0_SNR_10ER_20_nodes_deg_10_bandwidth_0.4\"\n",
    "\n",
    "r_signal = r_RcppCNPy.npyLoad(path_signal_to_load + '/2_signal.npy')\n",
    "print(r_base.dim(r_signal))\n",
    "gt_bkps = my_ut.open_json(path_signal_to_load + '/2_bkps.json')\n",
    "n_bkps = len(gt_bkps) - 1\n",
    "min_seg_length = 190\n",
    "windows_sizes = r_base.c(100) \n",
    "alpha = 0.3\n",
    "\n",
    "pred_bkps = detect_multiple_bkps(n_bkps=n_bkps, signal = r_signal, min_seg_length=min_seg_length, window_sizes=windows_sizes, alpha=alpha, bkps=[])\n",
    "print(pred_bkps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOWS_SIZES_LIST = [[30], [50], [100], [150]]\n",
    "for WINDOWS_SIZES in WINDOWS_SIZES_LIST:\n",
    "    NAME =  \"ER_20_nodes_deg_10_bandwidth_0.4\"\n",
    "    GRAPH_NAME =  NAME #\"exp_geo_20_nodes_av_deg_10\" #\"ER_20_nodes_deg_10_bandwidth_0.4_edge_prop_0.05\" \n",
    "    GRAPH_PATH =   \"data_1/graphs/clean_ER_with_bandwidth\"\n",
    "    SIGNAL_PATH = \"data_1/signal/within_hyp/noisy_varying_segment_length\"\n",
    "    SIGNAL_NAME =  \"large_x1.0_SNR_10\" + '_' + NAME\n",
    "    MAX_ID_SUBSET = 0\n",
    "    RESULT_DIR =  \"results_1/synthetic/within_hypothesis_noisy/varying_segment_length/r_covcp_experiments\" \n",
    "\n",
    "    R_COVCP_SEED = 42\n",
    "    NB_CORES = 2\n",
    "    LEVEL_ALPHA = 0.3\n",
    "    STABLE_SET_LENGTH = (20*19)//2\n",
    "    # WINDOWS_SIZES = [100]\n",
    "    RESULT_NAME = f\"test_alpha{LEVEL_ALPHA}_stablesetlength{STABLE_SET_LENGTH}_windows{'-'.join([str(w_s) for w_s in WINDOWS_SIZES])}\" \n",
    "\n",
    "    now = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    final_name = SIGNAL_NAME + \"_\" + RESULT_NAME\n",
    "    results_dir = os.path.join(RESULT_DIR, final_name)\n",
    "\n",
    "    # logging\n",
    "    graph_path = os.path.join(GRAPH_PATH, GRAPH_NAME)\n",
    "    signal_path = os.path.join(SIGNAL_PATH, SIGNAL_NAME)\n",
    "    graph_metadata = my_ut.open_json(f\"{graph_path}/00_graphs_metadata.json\")\n",
    "    signal_metadata = my_ut.open_json(f\"{signal_path}/00_signal_metadata.json\")\n",
    "    seg_length_hyp = \"large\"\n",
    "\n",
    "    covcp_description = \"Test on the different hyper-parameters to improve results understanding and parametrization\"\n",
    "    covcp_metadata = {\"datetime\": now, \"description\": covcp_description, \"commit hash\": my_ut.get_git_head_short_hash(), \"graph folder\": graph_path, \"graph metadata\": graph_metadata, \"signal folder\": SIGNAL_PATH + '/' + SIGNAL_NAME, \"signal metadata\": signal_metadata, \"r_covcp seed\": R_COVCP_SEED, \"level alpha\": LEVEL_ALPHA, \"windows sizes\": WINDOWS_SIZES, \"length of the stable set\": STABLE_SET_LENGTH, \"nb_cores\": NB_CORES, 'cpd algo func': detect_multiple_bkps.__name__}\n",
    "    covcp_results = {}\n",
    "\n",
    "    r_domc.registerDoMC(cores = NB_CORES)\n",
    "    r_base.set_seed(R_COVCP_SEED)\n",
    "    r_windows_sizes = r_base.c(WINDOWS_SIZES[0]) \n",
    "\n",
    "    # running CPD algorithms\n",
    "    for exp_id in tqdm(range(MAX_ID_SUBSET), desc='Running experiment...'):\n",
    "        exp_id = str(exp_id)\n",
    "        r_signal = r_RcppCNPy.npyLoad(signal_path + f'/{exp_id}_signal.npy')\n",
    "        gt_bkps = my_ut.open_json(signal_path + f'/{exp_id}_bkps.json')\n",
    "        run_r_covcp_algo(r_signal, gt_bkps, covcp_results, STABLE_SET_LENGTH, r_windows_sizes, LEVEL_ALPHA, exp_id)\n",
    "\n",
    "    my_ut.create_parent_and_dump_json(results_dir, \"covcp_metadata.json\", my_ut.turn_all_list_of_dict_into_str(covcp_metadata), indent=4)\n",
    "    # my_ut.create_parent_and_dump_json(results_dir, \"r_covcp_pred.json\", my_ut.turn_all_list_of_dict_into_str(covcp_results), indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments with ```HaotianXu/changepoints```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 4\n",
    "A1 = r_cp.gen_cov_mat(p, 1, \"equal\")\n",
    "print(type(A1))\n",
    "print(A1)\n",
    "print(type(A1[0]))\n",
    "print(A1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 10\n",
    "n_samples_1 = 300\n",
    "n_samples_2 = 300\n",
    "n_samples_3 = 300\n",
    "n_samples_4 = 300\n",
    "n_samples = n_samples_1 + n_samples_2 + n_samples_3 + n_samples_4\n",
    "A1 = r_cp.gen_cov_mat(p, 10, \"equal\")\n",
    "A2 = r_cp.gen_cov_mat(p, 10, \"diagonal\")\n",
    "A3 = r_cp.gen_cov_mat(p, 10, \"power\")\n",
    "A4 = r_cp.gen_cov_mat(p, 10, \"power\")\n",
    "X = r_base.cbind(r_base.t(r_mass.mvrnorm(n = n_samples_1, mu = r_base.rep(0, p), Sigma = A1)),\n",
    "r_base.t(r_mass.mvrnorm(n = n_samples_2, mu = r_base.rep(0, p), Sigma = A2)),\n",
    "r_base.t(r_mass.mvrnorm(n = n_samples_3, mu = r_base.rep(0, p), Sigma = A3)),\n",
    "r_base.t(r_mass.mvrnorm(n = n_samples_4, mu = r_base.rep(0, p), Sigma = A4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r_base.dim(r_mass.mvrnorm(n = n_samples_1, mu = r_base.rep(0, p), Sigma = A1)))\n",
    "print(r_base.dim(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_BS_cov = r_cp.BS_cov(X, 1, n_samples)\n",
    "\n",
    "print(type(simple_BS_cov))\n",
    "print(simple_BS_cov)\n",
    "print('length of the BS object:', r_base.length(simple_BS_cov))\n",
    "print(type(simple_BS_cov[0]))\n",
    "print(simple_BS_cov[0])\n",
    "print(type(simple_BS_cov[1]))\n",
    "print(simple_BS_cov[1])\n",
    "print(type(simple_BS_cov[2]))\n",
    "print(simple_BS_cov[2])\n",
    "print(type(simple_BS_cov[3]))\n",
    "print(simple_BS_cov[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 4\n",
    "threshoded_dBS = r_cp.thresholdBS(simple_BS_cov, 10)\n",
    "\n",
    "print(type(threshoded_dBS))\n",
    "print(threshoded_dBS)\n",
    "print('length of the thresholded BS object:', r_base.length(threshoded_dBS))\n",
    "print(type(threshoded_dBS[0]))\n",
    "print(threshoded_dBS[0])\n",
    "print(type(threshoded_dBS[1]))\n",
    "print(threshoded_dBS[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test on ```rpy2```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import utils as my_ut\n",
    "import result_related as my_res\n",
    "\n",
    "from datetime import datetime\n",
    "from typing import List\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ```rpy2``` utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Project '~/dev/graph-signals-change-point-detection' loaded. [renv 1.0.7]\n",
      "\n",
      "NOTE: Dependency discovery took 41 seconds during snapshot.\n",
      "Consider using .renvignore to ignore files, or switching to explicit snapshots.\n",
      "See `?renv::dependencies` for more information.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import rpy2\n",
    "import rpy2.robjects as robjects\n",
    "\n",
    "## To aid in printing HTML in notebooks\n",
    "import rpy2.ipython.html\n",
    "rpy2.ipython.html.init_printing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    WARNING: The R package \"reticulate\" only fixed recently\n",
      "    an issue that caused a segfault when used with rpy2:\n",
      "    https://github.com/rstudio/reticulate/pull/1188\n",
      "    Make sure that you use a version of that package that includes\n",
      "    the fix.\n",
      "    "
     ]
    }
   ],
   "source": [
    "from rpy2.robjects.packages import importr\n",
    "\n",
    "r_base = importr('base')\n",
    "r_utils = importr('utils')\n",
    "r_cp = importr('changepoints')\n",
    "r_covcp = importr('covcp')\n",
    "r_mass = importr('MASS')\n",
    "r_domc = importr('doMC')\n",
    "r_parallel = importr('parallel')\n",
    "r_RcppCNPy = importr('RcppCNPy')\n",
    "r_reticulate = importr('reticulate')\n",
    "\n",
    "rprint = robjects.globalenv.find(\"print\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nested_named_element_from_R_list(obj, named_elem:str):\n",
    "    nested_names_list = named_elem.split('$')\n",
    "    target_obj = obj\n",
    "    for name in nested_names_list:\n",
    "        if name.isdigit():\n",
    "            target_obj = target_obj.rx2(int(name))\n",
    "        else:\n",
    "            target_obj = target_obj.rx2(name)\n",
    "    return target_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def turn_r_bool_in_py_bool(r_bool):\n",
    "    str_r_bool = str(r_bool.rx2(1))[4:9]\n",
    "    return not str_r_bool == 'FALSE'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sandbox on CPD algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments with ```akopich/covcp```\n",
    "\n",
    "Comprehénsion de la méthode : \n",
    "\n",
    "- un cpd est déclaré si pour une des taille de fenêtres on atteint, pour un des points centraux (de la fenêtre) une valeur de la statistique supérieure à la valeur critique (le seuil) calculé pour cette taille de fenêtre. \n",
    "- a priori les valeurs critiques sont calculées grâce au bootstrap ('data-driven approach')\n",
    "- pour confirmer mon intuition sur la compréhension de la méthode :\n",
    "    - aller voir dans la résolution de l'algo si je trouve d'où viennent les \"critical values\" pour confirmer qu'elles sont bien calculées grâce au bootstrap\n",
    "    - a priori dans mon expérience on ne détecte le cp que pour la plus grande taillede fenêtre (parce que meilleure estimation ?)\n",
    "        - aller voir comment évoluent les valeurs de la critical value en fonction de la taille de la fenêtre\n",
    "        --> **les valeurs critiques diminuent systématiquement avec la taille des fenêtres considérées**\n",
    "        - éventuellement faire des plot pour assess tout ça, et comprendre un peu mieux grâce à l'article comment fonctionne le bootstrap\n",
    "    - concernant le niveau alpha :\n",
    "        - comment influence les résultats : revenir à la définition pour voir si cohérent\n",
    "        - voir si intervient bien dans le bootstrap au moment du calcul des valeurs critiques : censé les diminuer ou augmenter\n",
    "    - comment influence la taille de l'échantillon 'stable' pour le bootstrap ?\n",
    "        --> **jusque là, les expériences réalisées montrent que lorsqu'on diminue la taille du stableset, on diminue aussi les valeurs critiques**\n",
    "    - comment influence la taille des segments de stationarité ?\n",
    "\n",
    "A faire en code : \n",
    "\n",
    "- transformer les données python en données R (voir doc rpy2 sur le paragraphe associé)\n",
    "- implémenter la détection de plusieurs ruptures (relire ce qu'ils disent dans l'article à ce sujet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_covcp_localization(covcp_results, window_sizes):\n",
    "    # check if there is actually a cp to localize\n",
    "    is_there_cp = r_covcp.isRejected(covcp_results)\n",
    "    if not is_there_cp:\n",
    "        return None\n",
    "    # if so, return the smallest window in which the cp can be localized\n",
    "    ciritical_values = covcp_results.rx2('criticalValue')\n",
    "    for i, window_size in enumerate(window_sizes):\n",
    "        window_stat_results = get_nested_named_element_from_R_list(covcp_results, f'statistics$window2statistics${i+1}')\n",
    "        max_stat = window_stat_results.rx2('statistics')[0]\n",
    "        if max_stat > ciritical_values[i]:\n",
    "            central_points = window_stat_results.rx2('centralPoints')\n",
    "            stat_values_arr = np.asarray(window_stat_results.rx2('distances'))\n",
    "            stats_argmx = int(np.argmax(stat_values_arr))\n",
    "            central_point_argmax = central_points[stats_argmx]\n",
    "            return central_point_argmax, (central_point_argmax - window_size, central_point_argmax + window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_r_left_subsignal(signal: np.ndarray, split_id):\n",
    "    left_sub_signal_arr = np.copy(signal)[:split_id, :]\n",
    "    np.save(\"data_1/.temp/left_sub_signal.npy\", left_sub_signal_arr)\n",
    "    r_left_subsignal = r_RcppCNPy.npyLoad(\"data_1/.temp/left_sub_signal.npy\")\n",
    "    return r_left_subsignal\n",
    "\n",
    "\n",
    "def get_r_right_subsignal(signal: np.ndarray, split_id):\n",
    "    right_sub_signal_arr = np.copy(signal)[split_id:, :]\n",
    "    np.save(\"data_1/.temp/right_sub_signal.npy\", right_sub_signal_arr)\n",
    "    r_right_subsignal = r_RcppCNPy.npyLoad(\"data_1/.temp/right_sub_signal.npy\")\n",
    "    return r_right_subsignal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_multiple_bkps(n_bkps, signal, min_seg_length, window_sizes, alpha, bkps, left_offset=0):\n",
    "    bootstrap_stableSet = r_base.seq(1, min_seg_length)\n",
    "    cov_cp_stat_test = r_covcp.covTest(window_sizes, alpha, signal, r_covcp.noPattern, r_covcp.infNorm, bootstrap_stableSet)\n",
    "    cov_cp_loc = get_covcp_localization(cov_cp_stat_test, window_sizes)\n",
    "    if cov_cp_loc is None:\n",
    "        return bkps\n",
    "    else:\n",
    "        # add current bkp\n",
    "        cp, _ = cov_cp_loc\n",
    "        bkps.append(left_offset + cp)\n",
    "        if len(bkps) < n_bkps:\n",
    "            # apply to left and right subsignal\n",
    "            signal_arr = np.copy(np.asarray(signal))\n",
    "            if cp - 1 > 2*min_seg_length:\n",
    "                r_left_subsignal = get_r_left_subsignal(signal_arr, cp-1)\n",
    "                detect_multiple_bkps(n_bkps, r_left_subsignal, min_seg_length, window_sizes, alpha, bkps, left_offset=left_offset)\n",
    "            if signal_arr.shape[0] - cp + 1 > 2*min_seg_length:\n",
    "                r_right_subsignal = get_r_right_subsignal(signal_arr, cp-1)\n",
    "                detect_multiple_bkps(n_bkps, r_right_subsignal, min_seg_length, window_sizes, alpha, bkps, left_offset=left_offset+cp)\n",
    "        return bkps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_r_covcp_algo(r_signal, gt_bkps: List[int], covcp_results: dict, min_seg_length:int, window_sizes, alpha, exp_id):\n",
    "    # running CPD algorithm\n",
    "    t1 = time.perf_counter()\n",
    "    covcp_bkps = detect_multiple_bkps(n_bkps=len(gt_bkps)-1, signal=r_signal, min_seg_length=min_seg_length, window_sizes=window_sizes, alpha=alpha, bkps=[])\n",
    "    t2 = time.perf_counter()\n",
    "    covcp_bkps.sort()\n",
    "    covcp_bkps = [int(bkp) for bkp in covcp_bkps] + [r_base.dim(r_signal)[0]]\n",
    "    # logging\n",
    "    covcp_results[exp_id] = {}\n",
    "    covcp_results[exp_id][\"time\"] = round(t2 - t1, ndigits=3)\n",
    "    covcp_results[exp_id][\"pred\"] = covcp_bkps\n",
    "    covcp_results[exp_id][\"gt\"] = gt_bkps\n",
    "    covcp_results[exp_id][\"n_bkps\"] = len(gt_bkps)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 800  20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Signal generation\n",
    "p = 20\n",
    "n_samples_1 = 400\n",
    "n_samples_2 = 400\n",
    "n_samples = n_samples_1 + n_samples_2\n",
    "A1 = r_cp.gen_cov_mat(p, 10, \"equal\")\n",
    "A2 = r_cp.gen_cov_mat(p, 10, \"diagonal\")\n",
    "X = r_base.rbind(r_mass.mvrnorm(n = n_samples_1, mu = r_base.rep(0, p), Sigma = A1),\n",
    "    r_mass.mvrnorm(n = n_samples_2, mu = r_base.rep(0, p), Sigma = A2)\n",
    ")\n",
    "print(r_base.dim(X)[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 1000   20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Signal generation\n",
    "p = 20\n",
    "n_samples_1 = 400\n",
    "n_samples_2 = 400\n",
    "n_samples_3 = 200\n",
    "n_samples = n_samples_1 + n_samples_2 + n_samples_3\n",
    "A1 = r_cp.gen_cov_mat(p, 1, \"equal\")\n",
    "A2 = r_cp.gen_cov_mat(p, 1, \"diagonal\")\n",
    "A3 = r_cp.gen_cov_mat(p, 1, \"equal\")\n",
    "X_mult = r_base.rbind(r_mass.mvrnorm(n = n_samples_1, mu = r_base.rep(0, p), Sigma = A1),\n",
    "    r_mass.mvrnorm(n = n_samples_2, mu = r_base.rep(0, p), Sigma = A2), \n",
    "    r_mass.mvrnorm(n = n_samples_3, mu = r_base.rep(0, p), Sigma = A3)\n",
    ")\n",
    "print(r_base.dim(X_mult))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "windows = r_base.c(50) \n",
    "alpha = 0.3\n",
    "len_stable_set = 190"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_domc.registerDoMC(cores = 5)\n",
    "r_base.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bkps = detect_multiple_bkps(n_bkps=2, signal=X_mult, min_seg_length=len_stable_set, window_sizes=windows, alpha=alpha, bkps=[]) \n",
    "bkps.sort()\n",
    "print(bkps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_signal_to_load = \"data_1/signal/within_hyp/noisy_varying_segment_length/large_x1.0_SNR_10ER_20_nodes_deg_10_bandwidth_0.4\"\n",
    "\n",
    "r_signal = r_RcppCNPy.npyLoad(path_signal_to_load + '/2_signal.npy')\n",
    "print(r_base.dim(r_signal))\n",
    "gt_bkps = open_json(path_signal_to_load + '/2_bkps.json')\n",
    "n_bkps = len(gt_bkps) - 1\n",
    "min_seg_length = 190\n",
    "windows_sizes = r_base.c(100) \n",
    "alpha = 0.3\n",
    "\n",
    "pred_bkps = detect_multiple_bkps(n_bkps=n_bkps, signal = r_signal, min_seg_length=min_seg_length, window_sizes=windows_sizes, alpha=alpha, bkps=[])\n",
    "print(pred_bkps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running experiment...: 0it [00:00, ?it/s]\n",
      "Running experiment...: 0it [00:00, ?it/s]\n",
      "Running experiment...: 0it [00:00, ?it/s]\n",
      "Running experiment...: 0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "WINDOWS_SIZES_LIST = [[30], [50], [100], [150]]\n",
    "for WINDOWS_SIZES in WINDOWS_SIZES_LIST:\n",
    "    NAME =  \"ER_20_nodes_deg_10_bandwidth_0.4\"\n",
    "    GRAPH_NAME =  NAME #\"exp_geo_20_nodes_av_deg_10\" #\"ER_20_nodes_deg_10_bandwidth_0.4_edge_prop_0.05\" \n",
    "    GRAPH_PATH =   \"data_1/graphs/clean_ER_with_bandwidth\"\n",
    "    SIGNAL_PATH = \"data_1/signal/within_hyp/noisy_varying_segment_length\"\n",
    "    SIGNAL_NAME =  \"large_x1.0_SNR_10\" + '_' + NAME\n",
    "    MAX_ID_SUBSET = 0\n",
    "    RESULT_DIR =  \"results_1/synthetic/within_hypothesis_noisy/varying_segment_length/r_covcp_experiments\" \n",
    "\n",
    "    R_COVCP_SEED = 42\n",
    "    NB_CORES = 2\n",
    "    LEVEL_ALPHA = 0.3\n",
    "    STABLE_SET_LENGTH = (20*19)//2\n",
    "    # WINDOWS_SIZES = [100]\n",
    "    RESULT_NAME = f\"test_alpha{LEVEL_ALPHA}_stablesetlength{STABLE_SET_LENGTH}_windows{'-'.join([str(w_s) for w_s in WINDOWS_SIZES])}\" \n",
    "\n",
    "    now = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    final_name = SIGNAL_NAME + \"_\" + RESULT_NAME\n",
    "    results_dir = os.path.join(RESULT_DIR, final_name)\n",
    "\n",
    "    # logging\n",
    "    graph_path = os.path.join(GRAPH_PATH, GRAPH_NAME)\n",
    "    signal_path = os.path.join(SIGNAL_PATH, SIGNAL_NAME)\n",
    "    graph_metadata = my_ut.open_json(f\"{graph_path}/00_graphs_metadata.json\")\n",
    "    signal_metadata = my_ut.open_json(f\"{signal_path}/00_signal_metadata.json\")\n",
    "    seg_length_hyp = \"large\"\n",
    "\n",
    "    covcp_description = \"Test on the different hyper-parameters to improve results understanding and parametrization\"\n",
    "    covcp_metadata = {\"datetime\": now, \"description\": covcp_description, \"commit hash\": my_ut.get_git_head_short_hash(), \"graph folder\": graph_path, \"graph metadata\": graph_metadata, \"signal folder\": SIGNAL_PATH + '/' + SIGNAL_NAME, \"signal metadata\": signal_metadata, \"r_covcp seed\": R_COVCP_SEED, \"level alpha\": LEVEL_ALPHA, \"windows sizes\": WINDOWS_SIZES, \"length of the stable set\": STABLE_SET_LENGTH, \"nb_cores\": NB_CORES, 'cpd algo func': detect_multiple_bkps.__name__}\n",
    "    covcp_results = {}\n",
    "\n",
    "    r_domc.registerDoMC(cores = NB_CORES)\n",
    "    r_base.set_seed(R_COVCP_SEED)\n",
    "    r_windows_sizes = r_base.c(WINDOWS_SIZES[0]) \n",
    "\n",
    "    # running CPD algorithms\n",
    "    for exp_id in tqdm(range(MAX_ID_SUBSET), desc='Running experiment...'):\n",
    "        exp_id = str(exp_id)\n",
    "        r_signal = r_RcppCNPy.npyLoad(signal_path + f'/{exp_id}_signal.npy')\n",
    "        gt_bkps = my_ut.open_json(signal_path + f'/{exp_id}_bkps.json')\n",
    "        run_r_covcp_algo(r_signal, gt_bkps, covcp_results, STABLE_SET_LENGTH, r_windows_sizes, LEVEL_ALPHA, exp_id)\n",
    "\n",
    "    my_ut.create_parent_and_dump_json(results_dir, \"covcp_metadata.json\", my_ut.turn_all_list_of_dict_into_str(covcp_metadata), indent=4)\n",
    "    # my_ut.create_parent_and_dump_json(results_dir, \"r_covcp_pred.json\", my_ut.turn_all_list_of_dict_into_str(covcp_results), indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments with ```HaotianXu/changepoints```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 4\n",
    "A1 = r_cp.gen_cov_mat(p, 1, \"equal\")\n",
    "print(type(A1))\n",
    "print(A1)\n",
    "print(type(A1[0]))\n",
    "print(A1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 10\n",
    "n_samples_1 = 300\n",
    "n_samples_2 = 300\n",
    "n_samples_3 = 300\n",
    "n_samples_4 = 300\n",
    "n_samples = n_samples_1 + n_samples_2 + n_samples_3 + n_samples_4\n",
    "A1 = r_cp.gen_cov_mat(p, 10, \"equal\")\n",
    "A2 = r_cp.gen_cov_mat(p, 10, \"diagonal\")\n",
    "A3 = r_cp.gen_cov_mat(p, 10, \"power\")\n",
    "A4 = r_cp.gen_cov_mat(p, 10, \"power\")\n",
    "X = r_base.cbind(r_base.t(r_mass.mvrnorm(n = n_samples_1, mu = r_base.rep(0, p), Sigma = A1)),\n",
    "r_base.t(r_mass.mvrnorm(n = n_samples_2, mu = r_base.rep(0, p), Sigma = A2)),\n",
    "r_base.t(r_mass.mvrnorm(n = n_samples_3, mu = r_base.rep(0, p), Sigma = A3)),\n",
    "r_base.t(r_mass.mvrnorm(n = n_samples_4, mu = r_base.rep(0, p), Sigma = A4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r_base.dim(r_mass.mvrnorm(n = n_samples_1, mu = r_base.rep(0, p), Sigma = A1)))\n",
    "print(r_base.dim(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_BS_cov = r_cp.BS_cov(X, 1, n_samples)\n",
    "\n",
    "print(type(simple_BS_cov))\n",
    "print(simple_BS_cov)\n",
    "print('length of the BS object:', r_base.length(simple_BS_cov))\n",
    "print(type(simple_BS_cov[0]))\n",
    "print(simple_BS_cov[0])\n",
    "print(type(simple_BS_cov[1]))\n",
    "print(simple_BS_cov[1])\n",
    "print(type(simple_BS_cov[2]))\n",
    "print(simple_BS_cov[2])\n",
    "print(type(simple_BS_cov[3]))\n",
    "print(simple_BS_cov[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 4\n",
    "threshoded_dBS = r_cp.thresholdBS(simple_BS_cov, 10)\n",
    "\n",
    "print(type(threshoded_dBS))\n",
    "print(threshoded_dBS)\n",
    "print('length of the thresholded BS object:', r_base.length(threshoded_dBS))\n",
    "print(type(threshoded_dBS[0]))\n",
    "print(threshoded_dBS[0])\n",
    "print(type(threshoded_dBS[1]))\n",
    "print(threshoded_dBS[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

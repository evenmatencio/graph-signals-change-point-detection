{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test on ```rpy2```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import utils as my_ut\n",
    "import result_related as my_res\n",
    "import running_cpd as my_cpd\n",
    "\n",
    "from math import floor\n",
    "from datetime import datetime\n",
    "from typing import List\n",
    "from tqdm import tqdm\n",
    "from sklearn.covariance import log_likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ```rpy2``` utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rpy2\n",
    "import rpy2.robjects as robjects\n",
    "\n",
    "## To aid in printing HTML in notebooks\n",
    "import rpy2.ipython.html\n",
    "rpy2.ipython.html.init_printing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rpy2.robjects.packages import importr\n",
    "\n",
    "r_base = importr('base')\n",
    "r_utils = importr('utils')\n",
    "r_cp = importr('changepoints')\n",
    "r_covcp = importr('covcp')\n",
    "r_mass = importr('MASS')\n",
    "r_domc = importr('doMC')\n",
    "r_parallel = importr('parallel')\n",
    "r_RcppCNPy = importr('RcppCNPy')\n",
    "r_reticulate = importr('reticulate')\n",
    "r_glasso = importr('glasso')\n",
    "\n",
    "rprint = robjects.globalenv.find(\"print\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sandbox on CPD algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments with ```glasso```\n",
    "\n",
    "Je peux bien travailler avec la fonction loglikelihood de scikit learn, quitte à la ré-implémenter de mon côté (bien faire attention à ce que les signes soient les bons, qu'on ne maximise pas à l'envers). Ce qu'il reste donc à faire c'est de faire les calculs de matrices de précision avec la librairie R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_signal_path = 'data_1/.temp/1_left_sub_signal.npy'\n",
    "r_signal = r_RcppCNPy.npyLoad(some_signal_path)\n",
    "print(r_base.dim(r_signal)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pen_coef = r_covcp.chooseRho(r_signal)\n",
    "emp_cov = r_covcp.Cov(r_signal)\n",
    "glasso_invcov_mat = r_glasso.glasso(s=emp_cov, rho=pen_coef).rx2('wi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SYNTHETIC DATA ADAPTED\n",
    "##########################\n",
    "\n",
    "NAME =  \"ER_20_nodes_deg_10_bandwidth_0.4\"\n",
    "GRAPH_PATH = \"data_1/synthetic_data/graphs/clean_ER_with_bandwidth\"\n",
    "GRAPH_NAME =  NAME  #+ f\"_edge_prop_{EDGE_PROP}\" #\"exp_geo_20_nodes_av_deg_10\" #\"ER_20_nodes_deg_10_bandwidth_0.4_edge_prop_0.05\" \n",
    "# SIGNAL_PATH = \"sandbox/test/\" #\"data_1/signal/within_hyp/SNR_20_varying_segment_length\"\n",
    "SIGNAL_PATH = \"sandbox/test\"\n",
    "# SIGNAL_PATH = \"data_1/synthetic_data/signal/within_hyp/SNR_20_censor_breakdown/varying_nb_breakdowns\" #\"data_1/signal/within_hyp/SNR_20_varying_segment_length\"\n",
    "EXP_ID_LIST = list(range(0, 4))\n",
    "RESULT_DIR = \"sandbox/test/results\"\n",
    "LASSO_ALPHA = \"from_covcp_paper\"\n",
    "MIN_SEGMENT_LENGTH_COEF = 0.4\n",
    "SNR = 20\n",
    "BKPS_GAP_CONSTRAINT = \"large\"\n",
    "N_BKPS = 4\n",
    "NB_BREAKDOWN = 2\n",
    "BREAKDOWN_LENGTH = 300\n",
    "\n",
    "\n",
    "OTHER_GRAPH_SEED = 1\n",
    "\n",
    "NB_CORES = 1\n",
    "LEVEL_ALPHA = 0.3\n",
    "STABLE_SET_LENGTH = 80\n",
    "WINDOWS_SIZE = [80]\n",
    "COVCP_TEMP_ID = 1\n",
    "COVCP_SEED = 1\n",
    "\n",
    "LASSO_TEMP_ID = 1\n",
    "PEN_MULT_COEF_LIST = [7]\n",
    "\n",
    "now = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "# logging\n",
    "graph_path = os.path.join(GRAPH_PATH, GRAPH_NAME)\n",
    "graph_metadata = my_ut.open_json(f\"{graph_path}/00_graphs_metadata.json\")\n",
    "seg_length_hyp = \"minimal\"\n",
    "graph_rng = np.random.default_rng(OTHER_GRAPH_SEED)\n",
    "\n",
    "    \n",
    "# SIGNAL_NAME = f\"{BKPS_GAP_CONSTRAINT}_x{MIN_SEGMENT_LENGTH_COEF}_SNR_{round(SNR, 4)}\" +  f\"_NBbd_{NB_BREAKDOWN}_bklength_{BREAKDOWN_LENGTH}\" + \"_\" + GRAPH_NAME \n",
    "SIGNAL_NAME = f\"SNR_20_and_fixed_min_size_900_samples_and_bkdwn_ER_20_nodes_deg_10_bandwidth_0.4\"\n",
    "signal_path = os.path.join(SIGNAL_PATH, SIGNAL_NAME)\n",
    "signal_metadata = my_ut.open_json(f\"{signal_path}/00_signal_metadata.json\")\n",
    "\n",
    "RESULT_NAME = \"\"\n",
    "final_name = SIGNAL_NAME #+ \"_\" + RESULT_NAME\n",
    "results_dir = os.path.join(RESULT_DIR, final_name)\n",
    "\n",
    "exp_desc = \"Test of the graphical Lasso cost function: grid seach over the L1 penalty coefficient. Its value is fixed according to the fromula from the covcp paper and a multiplicative coefficient.\"\n",
    "experiment_metadata = {\"datetime\": now, \"description\": exp_desc, \"commit hash\": my_ut.get_git_head_short_hash(), \"graph folder\": graph_path, \"graph metadata\": graph_metadata, \"signal folder\": SIGNAL_PATH + '/' + SIGNAL_NAME, \"signal metadata\": signal_metadata, \"min segment length hypothesis\": seg_length_hyp, \"lasso penalty coefficient\": LASSO_ALPHA, \"level_alpha\": LEVEL_ALPHA, \"stable_set_length\": STABLE_SET_LENGTH, \"windows_size\": WINDOWS_SIZE, \"nb_cores\": NB_CORES, \"r_covcp_seed\": COVCP_SEED}\n",
    "\n",
    "# output formatting\n",
    "# lasso_results = {\"0\": 'INIT'}\n",
    "# lasso_name = f\"lasso_pred_pencoefmult_{PEN_COEF}.json\"\n",
    "# lasso_json_path = os.path.join(results_dir, lasso_name)\n",
    "# my_ut.create_parent_and_dump_json(results_dir, lasso_name, my_ut.turn_all_list_of_dict_into_str(lasso_results), indent=4)\n",
    "covcp_results = {\"0\": 'INIT'}\n",
    "covcp_name = f\"covcp_pred_windsize_{WINDOWS_SIZE[0]}.json\"\n",
    "covcp_json_path = os.path.join(results_dir, covcp_name)\n",
    "my_ut.create_parent_and_dump_json(results_dir, covcp_name, my_ut.turn_all_list_of_dict_into_str(covcp_results), indent=4)\n",
    "\n",
    "# running CPD algorithms\n",
    "# for exp_id in tqdm(range(MAX_ID_SUBSET), desc='Running experiment...'):\n",
    "for exp_id in EXP_ID_LIST:\n",
    "    print(f\"\\n\\tOver exp_id={exp_id}...\")\n",
    "    exp_id = str(exp_id)\n",
    "    G, signal, gt_bkps, min_size = my_ut.load_data(graph_path, signal_path, exp_id, seg_length_hyp)\n",
    "    signal_file_path = f\"{signal_path}/{exp_id}\"\n",
    "    # my_cpd.run_r_glasso_cpd_algo_and_store(signal, gt_bkps, lasso_json_path, exp_id, PEN_COEF, lasso_intermediate_temp_path)\n",
    "    my_cpd.run_r_covcp_cpd_algo_and_store(signal_file_path, gt_bkps, covcp_json_path, STABLE_SET_LENGTH, min_size, WINDOWS_SIZE, LEVEL_ALPHA, exp_id, NB_CORES, COVCP_SEED)\n",
    "    \n",
    "\n",
    "    # my_ut.create_parent_and_dump_json(results_dir, F\"lasso_pred_pencoefmult_{PEN_COEF}.json\", my_ut.turn_all_list_of_dict_into_str(lasso_results), indent=4)\n",
    "# my_ut.create_parent_and_dump_json(results_dir, \"experiment_metadata.json\", my_ut.turn_all_list_of_dict_into_str(experiment_metadata), indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### REAL DATA ADAPTED\n",
    "##########################\n",
    "\n",
    "# NAME =  \"ER_20_nodes_deg_10_bandwidth_0.4\"\n",
    "GRAPH_PATH = \"data/real_data/test_filtered_0.5-40_order_3_subsampled_8\"\n",
    "GRAPH_NAME =  \"KNN_4_64_ch_graph_mat_adj_order_signal_header\"\n",
    "SIGNAL_PATH = \"data/real_data/test_filtered_0.5-40_order_3_subsampled_8\" \n",
    "RESULT_DIR = \"results_1/real_data/test/filtered_0.5-40_order_3_subsampled_8\"\n",
    "LASSO_ALPHA = \"from_covcp_paper\"\n",
    "seg_length_hyp = \"minimal\"\n",
    "\n",
    "# GRAPH LASSO METHOD\n",
    "PEN_MULT_COEF_LIST = [4]\n",
    "\n",
    "# R COVCP METHOD\n",
    "R_COVCP_SEED = 42\n",
    "NB_CORES = 2\n",
    "LEVEL_ALPHA = 0.3\n",
    "STABLE_SET_LENGTH = 80\n",
    "WINDOWS_SIZE = [80]\n",
    "\n",
    "\n",
    "now = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "# logging\n",
    "graph_path = os.path.join(GRAPH_PATH, GRAPH_NAME)\n",
    "# graph_metadata = my_ut.open_json(f\"{graph_path}/00_graphs_metadata.json\")\n",
    "# graph_rng = np.random.default_rng(OTHER_GRAPH_SEED)\n",
    "\n",
    "for PEN_COEF in PEN_MULT_COEF_LIST:\n",
    "\n",
    "    print(f\"\\n\\n \\t Working with multiplicative coefficient: {PEN_COEF} \\n\")\n",
    "    \n",
    "    # SIGNAL_NAME = f\"{BKPS_GAP_CONSTRAINT}_x{MIN_SEGMENT_LENGTH_COEF}_SNR_{round(SNR, 4)}\" + \"_\" + GRAPH_NAME \n",
    "    SIGNAL_NAME = \"volunteerS007_exp04\"\n",
    "    signal_path = os.path.join(SIGNAL_PATH, SIGNAL_NAME)\n",
    "    # signal_metadata = my_ut.open_json(f\"{signal_path}/00_signal_metadata.json\")\n",
    "    \n",
    "    RESULT_NAME = f\"running_time_test_with_mult_coef_{PEN_COEF}_{LASSO_ALPHA}\"\n",
    "    final_name = SIGNAL_NAME + \"_\" + RESULT_NAME\n",
    "    results_dir = os.path.join(RESULT_DIR, final_name)\n",
    "\n",
    "    exp_desc = \"Test of the graphical Lasso cost function.\"\n",
    "    experiment_metadata = {\"datetime\": now, \"description\": exp_desc, \"commit hash\": my_ut.get_git_head_short_hash(), \"graph folder\": \"no graph\", \"graph metadata\": \"no graph\", \"signal folder\": SIGNAL_PATH + '/' + SIGNAL_NAME}\n",
    "\n",
    "    # output formatting\n",
    "    # statio_results = {}\n",
    "    # normal_results = {}\n",
    "    lasso_results = {}\n",
    "    covcp_results = {}\n",
    "\n",
    "    # running CPD algorithms\n",
    "    # for exp_id in tqdm(range(MAX_ID_SUBSET), desc='Running experiment...'):\n",
    "    # G, signal, gt_bkps, min_size = my_ut.load_data(graph_path, signal_path, exp_id, seg_length_hyp)\n",
    "    # signal = np.load(f\"{signal_path}_signal.npy\", allow_pickle=False).T\n",
    "    # bkps = my_ut.open_json(f\"{signal_path}_bkps.json\")\n",
    "    # run_r_glasso_cpd_algo(signal, gt_bkps, lasso_results, exp_id, PEN_COEF)\n",
    "    r_signal = r_base.t(r_RcppCNPy.npyLoad(signal_path + '_signal.npy'))\n",
    "    gt_bkps = my_ut.open_json(signal_path + '_bkps.json')\n",
    "    min_size = 64\n",
    "    run_r_covcp_algo(r_signal, gt_bkps, covcp_results, STABLE_SET_LENGTH, min_size, WINDOWS_SIZE, LEVEL_ALPHA, 0)\n",
    "\n",
    "    my_ut.create_parent_and_dump_json(results_dir, F\"r_covcp_level_{LEVEL_ALPHA}_stableset_{STABLE_SET_LENGTH}_adapted_windowsize_{WINDOWS_SIZE[0]}_pred.json\", my_ut.turn_all_list_of_dict_into_str(covcp_results), indent=4)\n",
    "    # my_ut.create_parent_and_dump_json(results_dir, F\"lasso_pred_pencoefmult_{PEN_COEF}.json\", my_ut.turn_all_list_of_dict_into_str(lasso_results), indent=4)\n",
    "\n",
    "# my_ut.create_parent_and_dump_json(results_dir, \"experiment_metadata.json\", my_ut.turn_all_list_of_dict_into_str(experiment_metadata), indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SYNTHETIC DATA ADAPTED\n",
    "###########################\n",
    "\n",
    "PRECI_RECALL_MARGIN = 5\n",
    "res_folder_root = \"results_1/synthetic/within_hypothesis_noisy/glasso_experiments/SNR_20_large_x0.4_1000_samples/4_bkps_large_x0.4_SNR_20_1000_samples_ER_20_nodes_deg_10_bandwidth_0.4_pen_coef_gridsearch_from_covcp_paper\"\n",
    "file_names = os.listdir(res_folder_root)\n",
    "# PRED_FOLDER = [os.path.join(res_folder_root, file_name) for file_name in file_names]  #'.txt' not in file_name]\n",
    "PRED_FOLDER = [res_folder_root]\n",
    "\n",
    "# pencoef_mult_list =  [1, 2, 4]\n",
    "# pencoef_mult_list =  [0.6, 0.8, 1.0, 1.2, 1.4, 6, 8, 10, 12, 14, 20, 30]\n",
    "# pencoef_mult_list =  [1, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 25]\n",
    "# pencoef_mult_list =  [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "pencoef_mult_list =  [0.001, 0.5, 1, 5, 10, 20, 100]\n",
    "\n",
    "for pred_dir in PRED_FOLDER:\n",
    "\n",
    "    # fetching predictions\n",
    "    data_stats = my_ut.open_json(f\"{pred_dir}/experiment_metadata.json\")\n",
    "\n",
    "    # output formatting\n",
    "    metrics_dic = {}\n",
    "    metrics_dic[\"pred_path\"] = pred_dir\n",
    "    metrics_dic[\"hyper-parameters\"] = data_stats\n",
    "    metrics_dic[\"hyper-parameters\"][\"metrics_margin\"] = PRECI_RECALL_MARGIN\n",
    "    full_results = {}\n",
    "\n",
    "    for pencoefmult in pencoef_mult_list:\n",
    "\n",
    "        lasso_pencoef_pred_dic = my_ut.open_json(f\"{pred_dir}/lasso_pred_pencoefmult_{pencoefmult}.json\")\n",
    "        pencoef_glasso_results = {\"recall\": {'raw': []}, \"precision\": {'raw': []}, \"f1_score\": {'raw': []}, \"hausdorff\": {'raw': []}, \"assignement_cost\": {'raw': []}, \"time\": {\"raw\": []}}\n",
    "\n",
    "        for exp_id in lasso_pencoef_pred_dic.keys():\n",
    "            # compute metrics\n",
    "            lasso_pred_bkps = my_ut.turn_str_of_list_into_list_of_int(lasso_pencoef_pred_dic[exp_id][\"pred\"])\n",
    "            gt_bkps = my_ut.turn_str_of_list_into_list_of_int(lasso_pencoef_pred_dic[exp_id][\"gt\"])\n",
    "            my_res.compute_and_update_metrics(gt_bkps, lasso_pred_bkps, pencoef_glasso_results, PRECI_RECALL_MARGIN)\n",
    "            my_res.compute_assignement_cost(gt_bkps, lasso_pred_bkps, pencoef_glasso_results)\n",
    "            pencoef_glasso_results[\"time\"][\"raw\"].append(lasso_pencoef_pred_dic[exp_id][\"time\"])\n",
    "\n",
    "        full_results[pencoefmult] = pencoef_glasso_results\n",
    "        \n",
    "    # results post-precessing and saving\n",
    "    full_results = my_res.compute_and_add_stat_on_metrics(full_results)\n",
    "    full_results[\"metadata\"] = metrics_dic\n",
    "    full_results = my_ut.turn_all_list_of_dict_into_str(full_results)\n",
    "    my_ut.create_parent_and_dump_json(pred_dir, f'metrics_{PRECI_RECALL_MARGIN}.json', full_results, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments with ```akopich/covcp```\n",
    "\n",
    "Comprehénsion de la méthode : \n",
    "\n",
    "- un cpd est déclaré si pour une des taille de fenêtres on atteint, pour un des points centraux (de la fenêtre) une valeur de la statistique supérieure à la valeur critique (le seuil) calculé pour cette taille de fenêtre. \n",
    "- a priori les valeurs critiques sont calculées grâce au bootstrap ('data-driven approach')\n",
    "- pour confirmer mon intuition sur la compréhension de la méthode :\n",
    "    - aller voir dans la résolution de l'algo si je trouve d'où viennent les \"critical values\" pour confirmer qu'elles sont bien calculées grâce au bootstrap\n",
    "    - a priori dans mon expérience on ne détecte le cp que pour la plus grande taillede fenêtre (parce que meilleure estimation ?)\n",
    "        - aller voir comment évoluent les valeurs de la critical value en fonction de la taille de la fenêtre\n",
    "        --> **les valeurs critiques diminuent systématiquement avec la taille des fenêtres considérées**\n",
    "        - éventuellement faire des plot pour assess tout ça, et comprendre un peu mieux grâce à l'article comment fonctionne le bootstrap\n",
    "    - concernant le niveau alpha :\n",
    "        - comment influence les résultats : revenir à la définition pour voir si cohérent\n",
    "        - voir si intervient bien dans le bootstrap au moment du calcul des valeurs critiques : censé les diminuer ou augmenter\n",
    "    - comment influence la taille de l'échantillon 'stable' pour le bootstrap ?\n",
    "        --> **jusque là, les expériences réalisées montrent que lorsqu'on diminue la taille du stableset, on diminue aussi les valeurs critiques**\n",
    "    - comment influence la taille des segments de stationarité ?\n",
    "\n",
    "A faire en code : \n",
    "\n",
    "- transformer les données python en données R (voir doc rpy2 sur le paragraphe associé)\n",
    "- implémenter la détection de plusieurs ruptures (relire ce qu'ils disent dans l'article à ce sujet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Signal generation\n",
    "p = 20\n",
    "n_samples_1 = 400\n",
    "n_samples_2 = 400\n",
    "n_samples = n_samples_1 + n_samples_2\n",
    "A1 = r_cp.gen_cov_mat(p, 10, \"equal\")\n",
    "A2 = r_cp.gen_cov_mat(p, 10, \"diagonal\")\n",
    "X = r_base.rbind(r_mass.mvrnorm(n = n_samples_1, mu = r_base.rep(0, p), Sigma = A1),\n",
    "    r_mass.mvrnorm(n = n_samples_2, mu = r_base.rep(0, p), Sigma = A2)\n",
    ")\n",
    "print(r_base.dim(X)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Signal generation\n",
    "p = 20\n",
    "n_samples_1 = 400\n",
    "n_samples_2 = 400\n",
    "n_samples_3 = 200\n",
    "n_samples = n_samples_1 + n_samples_2 + n_samples_3\n",
    "A1 = r_cp.gen_cov_mat(p, 1, \"equal\")\n",
    "A2 = r_cp.gen_cov_mat(p, 1, \"diagonal\")\n",
    "A3 = r_cp.gen_cov_mat(p, 1, \"equal\")\n",
    "X_mult = r_base.rbind(r_mass.mvrnorm(n = n_samples_1, mu = r_base.rep(0, p), Sigma = A1),\n",
    "    r_mass.mvrnorm(n = n_samples_2, mu = r_base.rep(0, p), Sigma = A2), \n",
    "    r_mass.mvrnorm(n = n_samples_3, mu = r_base.rep(0, p), Sigma = A3)\n",
    ")\n",
    "print(r_base.dim(X_mult))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "windows = r_base.c(50) \n",
    "alpha = 0.3\n",
    "len_stable_set = 190"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_domc.registerDoMC(cores = 5)\n",
    "r_base.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOWS_SIZES_LIST = [[30], [50], [100], [150]]\n",
    "for WINDOWS_SIZES in WINDOWS_SIZES_LIST:\n",
    "    NAME =  \"ER_20_nodes_deg_10_bandwidth_0.4\"\n",
    "    GRAPH_NAME =  NAME #\"exp_geo_20_nodes_av_deg_10\" #\"ER_20_nodes_deg_10_bandwidth_0.4_edge_prop_0.05\" \n",
    "    GRAPH_PATH =   \"data_1/graphs/clean_ER_with_bandwidth\"\n",
    "    SIGNAL_PATH = \"data_1/signal/within_hyp/noisy_varying_segment_length\"\n",
    "    SIGNAL_NAME =  \"large_x1.0_SNR_10\" + '_' + NAME\n",
    "    MAX_ID_SUBSET = 0\n",
    "    RESULT_DIR =  \"results_1/synthetic/within_hypothesis_noisy/varying_segment_length/r_covcp_experiments\" \n",
    "\n",
    "    R_COVCP_SEED = 42\n",
    "    NB_CORES = 2\n",
    "    LEVEL_ALPHA = 0.3\n",
    "    STABLE_SET_LENGTH = (20*19)//2\n",
    "    # WINDOWS_SIZES = [100]\n",
    "    RESULT_NAME = f\"test_alpha{LEVEL_ALPHA}_stablesetlength{STABLE_SET_LENGTH}_windows{'-'.join([str(w_s) for w_s in WINDOWS_SIZES])}\" \n",
    "\n",
    "    now = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    final_name = SIGNAL_NAME + \"_\" + RESULT_NAME\n",
    "    results_dir = os.path.join(RESULT_DIR, final_name)\n",
    "\n",
    "    # logging\n",
    "    graph_path = os.path.join(GRAPH_PATH, GRAPH_NAME)\n",
    "    signal_path = os.path.join(SIGNAL_PATH, SIGNAL_NAME)\n",
    "    graph_metadata = my_ut.open_json(f\"{graph_path}/00_graphs_metadata.json\")\n",
    "    signal_metadata = my_ut.open_json(f\"{signal_path}/00_signal_metadata.json\")\n",
    "    seg_length_hyp = \"large\"\n",
    "\n",
    "    covcp_description = \"Test on the different hyper-parameters to improve results understanding and parametrization\"\n",
    "    covcp_metadata = {\"datetime\": now, \"description\": covcp_description, \"commit hash\": my_ut.get_git_head_short_hash(), \"graph folder\": graph_path, \"graph metadata\": graph_metadata, \"signal folder\": SIGNAL_PATH + '/' + SIGNAL_NAME, \"signal metadata\": signal_metadata, \"r_covcp seed\": R_COVCP_SEED, \"level alpha\": LEVEL_ALPHA, \"windows sizes\": WINDOWS_SIZES, \"length of the stable set\": STABLE_SET_LENGTH, \"nb_cores\": NB_CORES, 'cpd algo func': detect_multiple_bkps.__name__}\n",
    "    covcp_results = {}\n",
    "\n",
    "    r_domc.registerDoMC(cores = NB_CORES)\n",
    "    r_base.set_seed(R_COVCP_SEED)\n",
    "    r_windows_sizes = r_base.c(WINDOWS_SIZES[0]) \n",
    "\n",
    "    # running CPD algorithms\n",
    "    for exp_id in tqdm(range(MAX_ID_SUBSET), desc='Running experiment...'):\n",
    "        exp_id = str(exp_id)\n",
    "        r_signal = r_RcppCNPy.npyLoad(signal_path + f'/{exp_id}_signal.npy')\n",
    "        gt_bkps = my_ut.open_json(signal_path + f'/{exp_id}_bkps.json')\n",
    "        run_r_covcp_algo(r_signal, gt_bkps, covcp_results, STABLE_SET_LENGTH, r_windows_sizes, LEVEL_ALPHA, exp_id)\n",
    "\n",
    "    my_ut.create_parent_and_dump_json(results_dir, \"covcp_metadata.json\", my_ut.turn_all_list_of_dict_into_str(covcp_metadata), indent=4)\n",
    "    # my_ut.create_parent_and_dump_json(results_dir, \"r_covcp_pred.json\", my_ut.turn_all_list_of_dict_into_str(covcp_results), indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments with ```HaotianXu/changepoints```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 4\n",
    "A1 = r_cp.gen_cov_mat(p, 1, \"equal\")\n",
    "print(type(A1))\n",
    "print(A1)\n",
    "print(type(A1[0]))\n",
    "print(A1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 10\n",
    "n_samples_1 = 300\n",
    "n_samples_2 = 300\n",
    "n_samples_3 = 300\n",
    "n_samples_4 = 300\n",
    "n_samples = n_samples_1 + n_samples_2 + n_samples_3 + n_samples_4\n",
    "A1 = r_cp.gen_cov_mat(p, 10, \"equal\")\n",
    "A2 = r_cp.gen_cov_mat(p, 10, \"diagonal\")\n",
    "A3 = r_cp.gen_cov_mat(p, 10, \"power\")\n",
    "A4 = r_cp.gen_cov_mat(p, 10, \"power\")\n",
    "X = r_base.cbind(r_base.t(r_mass.mvrnorm(n = n_samples_1, mu = r_base.rep(0, p), Sigma = A1)),\n",
    "r_base.t(r_mass.mvrnorm(n = n_samples_2, mu = r_base.rep(0, p), Sigma = A2)),\n",
    "r_base.t(r_mass.mvrnorm(n = n_samples_3, mu = r_base.rep(0, p), Sigma = A3)),\n",
    "r_base.t(r_mass.mvrnorm(n = n_samples_4, mu = r_base.rep(0, p), Sigma = A4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r_base.dim(r_mass.mvrnorm(n = n_samples_1, mu = r_base.rep(0, p), Sigma = A1)))\n",
    "print(r_base.dim(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_BS_cov = r_cp.BS_cov(X, 1, n_samples)\n",
    "\n",
    "print(type(simple_BS_cov))\n",
    "print(simple_BS_cov)\n",
    "print('length of the BS object:', r_base.length(simple_BS_cov))\n",
    "print(type(simple_BS_cov[0]))\n",
    "print(simple_BS_cov[0])\n",
    "print(type(simple_BS_cov[1]))\n",
    "print(simple_BS_cov[1])\n",
    "print(type(simple_BS_cov[2]))\n",
    "print(simple_BS_cov[2])\n",
    "print(type(simple_BS_cov[3]))\n",
    "print(simple_BS_cov[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 4\n",
    "threshoded_dBS = r_cp.thresholdBS(simple_BS_cov, 10)\n",
    "\n",
    "print(type(threshoded_dBS))\n",
    "print(threshoded_dBS)\n",
    "print('length of the thresholded BS object:', r_base.length(threshoded_dBS))\n",
    "print(type(threshoded_dBS[0]))\n",
    "print(threshoded_dBS[0])\n",
    "print(type(threshoded_dBS[1]))\n",
    "print(threshoded_dBS[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
